fcast_outTsum <- apply(fcast_outT,2,quantile,probs=c(0.025,0.5,0.975))
rm(list=ls())
library(tidyverse)
library(scales)
library(sf)
library(zoo)
library(Matrix)
library(janitor)
library(lubridate)
#library(snowfall)
library(stats)
library(cowplot)
### data folder - actually same as above
data_folder_bmgf = '~/polio-immunity-mapping/results/'
data_folder_lshtm = '~/Dropbox/Polio outbreak modeling/data/'
data_folder = if_else(dir.exists(data_folder_bmgf),data_folder_bmgf,'')
data_folder = if_else(dir.exists(data_folder_lshtm),data_folder_lshtm,data_folder)
### output folder
output_folder_bmgf = '~/polio-immunity-mapping/results/'
out_folder_lshtm = '~/Dropbox/Polio outbreak modeling/scenarios/'
out_folder = if_else(dir.exists(out_folder_bmgf),out_folder_bmgf,'')
out_folder = if_else(dir.exists(out_folder_lshtm),out_folder_lshtm,'')
# correct filenames for each collaborator
filename_shapes_bmgf = "~/Dropbox (Gates Foundation)/POLIS/"
filename_shapes_idm = "Q:/Data/Polis/polis_geodatabases/downloaded_20191209/WHO_POLIO_GLOBAL_GEODATABASE.gdb"
filename_shapes_lshtm = "~/Dropbox/POLIS/"
if(dir.exists(filename_shapes_bmgf)) filename_shapes = filename_shapes_bmgf
if(dir.exists(filename_shapes_idm))  filename_shapes = filename_shapes_idm
if(dir.exists(filename_shapes_lshtm))  filename_shapes = filename_shapes_lshtm
# correct filenames for each collaborator
filename_R_bmgf = "~/polio-immunity-mapping/"
filename_R_idm = "Q:/Data/Polis/polis_geodatabases/downloaded_20191209/WHO_POLIO_GLOBAL_GEODATABASE.gdb"
filename_R_lshtm = "~/Documents/GitHub/polio-immunity-mapping/"
if(dir.exists(filename_R_bmgf)) filename_R = filename_R_bmgf
if(dir.exists(filename_R_idm))  filename_R = filename_R_idm
if(dir.exists(filename_R_lshtm))  filename_R = filename_R_lshtm
# data
dupdate = "2020-07-10" %>% as.Date()
scen <- "siasx" #"siasx"#"novac" # sias
data_file = paste0(data_folder,'afro_emro_tsir_data_',scen,'_Jul_10_2020.csv')
data= read_csv(data_file)
# shapefile stuff
shapes_file = paste0(filename_shapes,"WHO_POLIO_GLOBAL_GEODATABASE.gdb")
shape2 = st_read(shapes_file,layer = 'GLOBAL_ADM2') %>% clean_names()
key2 = shape2 %>% st_drop_geometry() %>% filter(enddate > today()) %>% as_tibble %>%
filter(guid %in% data$guid)
key2$j <- 1:dim(key2)[1]
index_isolates = read_csv(index_isolates_file)
shape2 = st_read(shapes_file,layer = 'GLOBAL_ADM2') %>% clean_names()
shape1 = read_sf(shapes_file,layer = 'GLOBAL_ADM1') %>% clean_names()
raneff_file = paste0(out_folder,"wpv1_random_effects.csv")
raneff_tab = read_csv(raneff_file)
####
key2 = shape2 %>% st_drop_geometry() %>% filter(enddate > today()) %>% as_tibble %>%
filter(guid %in% data$guid)
dim(key2)
shape1 = shape1 %>% filter(enddate > today() | adm0_name == 'IRAQ',adm0_name %in% key2$adm0_name)
shape0 = read_sf(shapes_file,layer = 'GLOBAL_ADM0') %>% clean_names()
shape0 = shape0 %>% filter(enddate > today(),adm0_name %in% key2$adm0_name)
key2 = left_join(key2,area_index) %>% arrange(j)
key2 = left_join(key2,data %>% filter(period == 2020) %>% distinct(j,population))
rm(data)
load(file=paste0(out_folder,"data_analysis_",scen,"scen_",dupdate,".Rdata"))
dim(data)
dim(key2)
#load(file=paste0(out_folder,"fcast_100iter_novac_10fcast_2020.25periodend_2maxcases_2020-07-10.Rdat"))
load(file=paste0(out_folder,"fcast_100iter_novac_Yesintervene_10fcast_2020.25periodend_2maxcases_2020-07-10.Rdat"))
nvac <- tmp
#load(file=paste0(out_folder,"fcast_100iter_siasx_10fcast_2020.25periodend_2maxcases_2020-07-10.Rdat"))
load(file=paste0(out_folder,"fcast_100iter_siasx_Yesintervene_10fcast_2020.25periodend_2maxcases_2020-07-10.Rdat"))
siax <- tmp
rm(tmp)
# compare expected number of polio cases
out <- left_join(nvac,siax,by=c("Iter","guid"))
names(out)
key2_short <- key2 %>% select(adm0_name,adm1_name,adm2_name,guid)
out <- left_join(out,key2_short,by=c("guid"))
# so we only really want to compare total.y and total.x
output <- out %>% group_by(adm0_name,Iter) %>%
#summarize(nvac=sum(V7_12.x),siax=sum(V7_12.y))
summarize(nvac=sum(total.x),siax=sum(total.y))
country_compare <- output %>% group_by(adm0_name) %>%
summarize(nvactavg=quantile(nvac,0.5,na.rm = T),nvactlwr=quantile(nvac,0.025,na.rm = T),nvactupr=quantile(nvac,0.975,na.rm = T),
siaxtavg=quantile(siax,0.5,na.rm = T),siaxtlwr=quantile(siax,0.025,na.rm = T),siaxtupr=quantile(siax,0.975,na.rm = T)) %>%
mutate(avgd=nvactavg-siaxtavg,lwrd=nvactlwr-siaxtlwr,uprd=nvactupr-siaxtupr)
tmp <- country_compare[country_compare$avgd>0,]  # small number are -1 but that's ok - none are more than this
tmp$name <- recode(tmp$adm0_name,'DEMOCRATIC REPUBLIC OF THE CONGO' = "DRC",
'CENTRAL AFRICAN REPUBLIC' = "CAR",
'UNITED REPUBLIC OF TANZANIA'="TANZANIA",
'IRAN (ISLAMIC REPUBLIC OF)' = "IRAN",
'SYRIAN ARAB REPUBLIC' = "SYRIA",
'WEST BANK AND GAZA STRIP' = "WEST BANK",
'UNITED ARAB EMIRATES'="UAE",
'EQUATORIAL GUINEA' = "E GUINEA"
)
png(paste0(out_folder,"estimated_polio_cases_prevented_intervene_2020-07-10.png"),
width = 480*0.9, height = 480*0.5, units = "px", pointsize = 12,bg = "white")
ggplot(tmp,aes(x=name,y=avgd)) +
geom_bar(stat="identity") + theme_bw() +
theme(axis.text.x = element_text(angle=90,vjust=0.5)) +
xlab("") + ylab("Poliomyelitis cases \nprevented through SIAs")
dev.off()
write.csv(country_compare,paste0(out_folder,"country_compare_intervene.csv"),row.names=F)
# **** temporal comparison
load(file=paste0(out_folder,"siasx_scen_model_fit_2020-07-10.Rdat"))  # var "output"
# add additional data
t1 <- tibble(period=seq(2020+(4/12),2021,1/12),observed_totals=rep(NA,9),
fit_totals=rep(NA,9),se_totals=rep(NA,9),lead=rep(NA,9),lower=rep(NA,9),upper=rep(NA,9))
output <- rbind(output,t1)
# want number of cases within each iteration
covs <- paste0("V",seq(1,10))
#fcast_outT <- tmp %>% group_by(Iter) %>%
# look at this later...  summarise(across(covs, ~ sum(.x,na.rm=T)))
fcast_times <- 10
t2 <- left_join(nvac,siax,by=c("Iter","ID"))
t2$V1.x <- as.numeric(t2$V1.x>0)
t2$V2.x <- as.numeric(t2$V2.x>0)
t2$V3.x <- as.numeric(t2$V3.x>0)
t2$V4.x <- as.numeric(t2$V4.x>0)
t2$V5.x <- as.numeric(t2$V5.x>0)
t2$V6.x <- as.numeric(t2$V6.x>0)
t2$V7.x <- as.numeric(t2$V7.x>0)
t2$V8.x <- as.numeric(t2$V8.x>0)
t2$V9.x <- as.numeric(t2$V9.x>0)
t2$V10.x <- as.numeric(t2$V10.x>0)
t2$V1.y <- as.numeric(t2$V1.y>0)
t2$V2.y <- as.numeric(t2$V2.y>0)
t2$V3.y <- as.numeric(t2$V3.y>0)
t2$V4.y <- as.numeric(t2$V4.y>0)
t2$V5.y <- as.numeric(t2$V5.y>0)
t2$V6.y <- as.numeric(t2$V6.y>0)
t2$V7.y <- as.numeric(t2$V7.y>0)
t2$V8.y <- as.numeric(t2$V8.y>0)
t2$V9.y <- as.numeric(t2$V9.y>0)
t2$V10.x <- as.numeric(t2$V10.y>0)
fcast_outT <- t2 %>% select(-guid.x,-guid.y) %>% group_by(Iter) %>%
summarize_all(.funs=sum)
fcast_outTsum <- apply(fcast_outT,2,quantile,probs=c(0.025,0.5,0.975),na.rm=T)
fcast_compare_nvac <- as_tibble(cbind(period=round(seq(2020+3/12,2020+((fcast_times+2)*(1/12)),1/12),2),
fit_totals=fcast_outTsum[2,1:fcast_times+1],
lower=fcast_outTsum[1,1:fcast_times+1],
upper=fcast_outTsum[3,1:fcast_times+1]))
fcast_compare_siax <- as_tibble(cbind(period=round(seq(2020+3/12,2020+((fcast_times+2)*(1/12)),1/12),2),
fit_totals=fcast_outTsum[2,12+(1:fcast_times+1)],
lower=fcast_outTsum[1,12+(1:fcast_times+1)],
upper=fcast_outTsum[3,12+(1:fcast_times+1)]))
output$period <- round(output$period,2)
o2 <- left_join(output,fcast_compare_nvac,by=c("period"="period"))
o2 <- left_join(o2,fcast_compare_siax,by=c("period"="period"))
names(o2)
o2 <- o2 %>% filter(period<2021)
png(paste0(out_folder,"compare_forecast_",2,"maxcases_intervene_2020-07-10.png"),width=480*0.9,height=480*0.4,units="px",pointsize=12)
ggplot(o2,aes(x=period,y=observed_totals)) + geom_point() +
geom_line(aes(x=period,y=lower.x),linetype = "dashed") +  # (fitted)
geom_line(aes(x=period,y=upper.x),linetype = "dashed") +  # (fitted)
geom_line(aes(x=period,y=fit_totals.x),size=1.5) +        # (fitted)
geom_line(aes(x=period,y=lower.y),linetype = "dashed",col="grey50") + # (novacc)
geom_line(aes(x=period,y=upper.y),linetype = "dashed",col="grey50") +
geom_line(aes(x=period,y=fit_totals.y),col="grey50",size=1.5) +
xlim(2019.9,2021) +
geom_line(aes(x=period,y=fit_totals),col="darkgreen",size=1.5) +     # (siasx)
geom_line(aes(x=period,y=lower),col="darkgreen",linetype = "dashed") +
geom_line(aes(x=period,y=upper),col="darkgreen",linetype = "dashed") +
theme_bw() +
ylab("Number of districts with cVDPV2 cases")
dev.off()
png(paste0(out_folder,"compare_forecast_",2,"maxcases_intervene_2020-07-10.png"),width=480*0.9,height=480*0.4,units="px",pointsize=12)
ggplot(o2,aes(x=period,y=observed_totals)) + geom_point() +
geom_line(aes(x=period,y=lower.x),linetype = "dashed") +  # (fitted)
geom_line(aes(x=period,y=upper.x),linetype = "dashed") +  # (fitted)
geom_line(aes(x=period,y=fit_totals.x),size=1.5) +        # (fitted)
geom_line(aes(x=period,y=lower.y),linetype = "dashed",col="grey50") + # (novacc)
geom_line(aes(x=period,y=upper.y),linetype = "dashed",col="grey50") +
geom_line(aes(x=period,y=fit_totals.y),col="grey50",size=1.5) +
xlim(2019.9,2021) +
geom_line(aes(x=period,y=fit_totals),col="darkgreen",size=1.5) +     # (siasx)
geom_line(aes(x=period,y=lower),col="darkgreen",linetype = "dashed") +
geom_line(aes(x=period,y=upper),col="darkgreen",linetype = "dashed") +
theme_bw() +
ylab("Number of districts with \ncVDPV2 cases")
dev.off()
?rbinom
ns<-c(10,20,40,80,160)
xs<-rbinom(ns,size=1,p=0.5)
xs
xs<-sapply(ns,rbinom(ns,size=1,p=0.5))
x1<-rbinom(n=ns[1],size=1,p=0.5)
x1
sum(x1)
7.7*117154/(1000*52.18)
1/(365/52*70)
#library(tidyverse)
#library(janitor)
library(ggplot2)
rm(list = ls(all = TRUE))
dat <- read_csv("~/Dropbox/Dropbox/Teaching-LSHTM/DataScience/Session06-continuousdist/MindsetMatters.csv") %>% clean_names()
dat <- read_csv("~/Dropbox/Dropbox/Teaching-LSHTM/DataScience/Session06-continuousdist/MindsetMatters.csv")
dat <- read.csv("~/Dropbox/Dropbox/Teaching-LSHTM/DataScience/Session06-continuousdist/MindsetMatters.csv")
dat
head(dat)
dat <- dat[!is.na(dat$bmi),]
dat$ht <- sqrt(dat$Wt/dat$BMI)
plot(dat$ht,dat$Wt)
dat$ht
dat$Wt
dat <- read.csv("~/Dropbox/Dropbox/Teaching-LSHTM/DataScience/Session06-continuousdist/MindsetMatters.csv")
head(dat)
dat <- dat[!is.na(dat$BMI),]
dat$ht <- sqrt(dat$Wt/dat$BMI)
plot(dat$ht,dat$Wt)
plot(dat$BMI,dat$Syst)
plot(dat$Diast,dat$Syst)
plot(dat$ht,dat$Wt)
plot(dat$BMI,dat$Fat)
tapply(dat$Wt,dat$Cond,mean)
tapply(dat$Wt2,dat$Cond,mean)
plot(dat$BMI,dat$Fat)
plot(dat$Diast,dat$Syst)
plot(dat$BMI,dat$Syst)
plot(dat$BMI,dat$Diast)
plot(dat$BMI,dat$Fat)
mu <- round(mean(dat$Fat),2)
dat <- read.csv("~/Dropbox/Dropbox/Teaching-LSHTM/DataScience/Session06-continuousdist/MindsetMatters.csv")
head(dat)
dat <- dat[!is.na(dat$BMI),]
mu <- round(mean(dat$Fat),2)
mu <- round(mean(dat$Fat,na.rm=T),2)
?cor
?runif
Iter <- 100
Xss <- runif(Iter,500,121000)
Xsd <- runif(Iter,72,470)
# estimate amount of virus shed per day
Xvd <- Xvs*Xsd
Xvs <- runif(Iter,500,121000)
Xsd <- runif(Iter,72,470)
# estimate amount of virus shed per day
Xvd <- Xvs*Xsd
density(Xvd)
plot(density(Xvd))
summary(Xvd)
Iter <- 1000
Xvs <- runif(Iter,500,121000)
Xsd <- runif(Iter,72,470)
# estimate amount of virus shed per day
Xvd <- Xvs*Xsd
plot(density(Xvd))
summary(Xvd)
sd(Xvd)
plot(density(log(Xvd)))
plot(density(log10(Xvd)))
summary(Xvd)
plot(density(Xvd))
summary(Xvd)
hist(Xvd)
# maybe this should be N?
Xsd_mu <- (470-72)+72
# maybe this should be N?
Xsd_mu <- ((470-72)/2)+72
Xsd_sd <- (470-72)/4
?rnorm
Xsd <- rnorm(Iter,Xsd_mu,Xsd_sd)
hist(Xsd)
Xsd <- rlnorm(Iter,Xsd_mu,Xsd_sd)
hist(Xsd)
Xsd <- rlnorm(Iter,log(Xsd_mu),Xsd_sd)
hist(Xsd)
?rlnorm
Xsd <- rlnorm(Iter,log(Xsd_mu),log(Xsd_sd))
hist(Xsd)
X <- rlnorm(Iter)
hist(X)
X <- rlnorm(Iter,5,1)
hist(X)
summary(X)
X <- rlnorm(Iter,log(5),1)
hist(X)
summary(X)
log(5)
X <- rlnorm(Iter,log(5),log(1))
hist(X)
summary(X)
log(1)
X <- rlnorm(Iter,log(5),log(2))
hist(X)
summary(X)
sd(X)
X <- rlnorm(Iter,log(5),2)
hist(X)
summary(X)
sd(X)
X <- rlnorm(Iter,log(5),log(2))
X <- rlnorm(Iter,log(5),log(2))
hist(X)
summary(X)
sd(X)
Xsd <- rlnorm(Iter,log(Xsd_mu),log(Xsd_sd))
hist(Xsd)
summary(Xsd)
Xsd_mu
sd(Xsd)
log(Xsd_sd)
Xsd <- rlnorm(Iter,log(Xsd_mu),2)
hist(Xsd)
summary(Xsd)
sd(Xsd)
Xsd <- rlnorm(Iter,log(Xsd_mu),1)
hist(Xsd)
summary(Xsd)
sd(Xsd)
Xsd <- rlnorm(Iter,log(Xsd_mu),0.5)
#Xsd <- runif(Iter,72,470)
# maybe this should be N?
Xsd_mu <- ((470-72)/2)+72
Xsd_sd <- (470-72)/4
Xsd <- rlnorm(Iter,log(Xsd_mu),0.5)
hist(Xsd)
summary(Xsd)
sd(Xsd)
Xsd <- rlnorm(Iter,log(Xsd_mu),0.3)
hist(Xsd)
summary(Xsd)
sd(Xsd)
# estimate amount of virus shed per day
Xvd <- Xvs*Xsd
hist(Xvd)
summary(Xvd)
sd(Xvd)
median(Xvd)
exp(0.3)
library(ggplot2)
dat <- data.frame(x=Xvd)
ggplot(dat,aes(x=x)) + geom_histogram(fill="steelblue")
dat <- data.frame(Xvd=Xvd)
ggplot(dat,aes(x=Xvd)) + geom_histogram(fill="steelblue")
ggplot(dat,aes(x=Xvd)) + geom_histogram(fill="steelblue",col="grey80")
N <- 100000
V <- 10000
VD <- V*N
N <- 100000
V <- 10
VD <- V*N  # litres
# ok so the Xvd gets diluted within VD litres
Svd <- Xvd/VD
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80")
# ok so the Xvd gets diluted within VD litres
Svd <- Xvd/VD/2  # 500 ml sample
dat <- data.frame(Svd=Svd)
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80")
?geom_vline
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80") +
geom_vline(xintercept=2,col="red")
sum(Svd>2)/Iter
sum(Svd>1)/Iter
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80") +
geom_vline(xintercept=1,col="red")
2*50
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80") +
geom_vline(xintercept=100,col="red")
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80") #+
OutVals <- rep(0,length(Ninfe))
Ninfe <- c(1,10,20,50,100,1000)
OutVals <- rep(0,length(Ninfe))
Ninfe <- c(1,10,20,50,100,1000)
OutVals <- rep(0,length(Ninfe))
PrVals <- rep(0,length(Ninfe))
N <- 100000
V <- 10
VD <- V*N  # litres
for(i in 1:length(Ninfe)){
Xvdp <- Xvd*Ninfe[i]
# ok so the Xvd gets diluted within VD litres
Svd <- Xvd/VD/2  # 500 ml sample
OutVals[i] <- median(Svd)
PrVals[i] <- sum(Svd>100)/Iter
}
PrVals
OutVals
for(i in 1:length(Ninfe)){
Xvdp <- Xvd*Ninfe[i]
# ok so the Xvd gets diluted within VD litres
Svd <- Xvdp/VD/2  # 500 ml sample
OutVals[i] <- median(Svd)
PrVals[i] <- sum(Svd>100)/Iter
}
OutVals
PrVals
dat <- data.frame(Ninfe=Ninfe,OutVals=OutVals,PrVals=PrVals)
ggplot(dat,aes(x=Ninfe,y=PrVals)) + geom_point() + geom_line()
Ninfe <- c(1,10,20,50,100,500)
OutVals <- rep(0,length(Ninfe))
PrVals <- rep(0,length(Ninfe))
N <- 100000
V <- 10
VD <- V*N  # litres
for(i in 1:length(Ninfe)){
Xvdp <- Xvd*Ninfe[i]
# ok so the Xvd gets diluted within VD litres
Svd <- Xvdp/VD/2  # 500 ml sample
OutVals[i] <- median(Svd)
PrVals[i] <- sum(Svd>100)/Iter
}
dat <- data.frame(Ninfe=Ninfe,OutVals=OutVals,PrVals=PrVals)
ggplot(dat,aes(x=Ninfe,y=PrVals)) + geom_point() + geom_line()
ggplot(dat,aes(x=Svd)) + geom_histogram(fill="steelblue",col="grey80") #+
ggplot(dat,aes(x=Ninfe,y=PrVals)) + geom_point() + geom_line() +
labs(x="Number infected")
ggplot(dat,aes(x=Ninfe,y=PrVals)) + geom_point() + geom_line() +
labs(x="Number infected",y="Pr(virus being baove detection limit)")
PrVals
3*.5
3*2.5
6*12*2.5
#library(tidyverse)
#library(janitor)
library(ggplot2)
rm(list = ls(all = TRUE))
library(boot)
dat <- read.csv("~/Documents/GitHub/jupyter-notebook-shds/Practicals/Datasets/MotherBaby/baby.csv")
head(dat)
View(dat)
y <- data.frame(age_log=log(dat$Birth.Weight))
ggplot(dat,aes(x=Birth.Weight)) + geom_histogram()
is.na(dat$Birth.Weight)
sum(is.na(dat$Birth.Weight))
head(dat)
sum(is.na(dat$Gestational.Days))
sum(is.na(dat$Maternal.Age))
sum(is.na(dat$Maternal.Height))
sum(is.na(dat$Maternal.Pregnancy.Weight))
sum(is.na(dat))
head(dat)
ggplot(dat,aes(x=Birth.Weight)) + geom_histogram()
ggplot(dat,aes(sample=Birth.Weight)) + stat_qq()
install("devtools")
install.packages("devtools")
install.packages(c("janitor", "tidyverse"))
# explore the data from Jeddah
library(tidyverse)
library(janitor)
library(ggplot2)
setwd("~/Dropbox/COVID-WBE/random")
vir <- read_csv("Copy of Data summary_overall.csv") %>% clean_names()
meta <- read_csv("Copy of Waste water TOC Result.csv") %>% clean_names()
# create linkable dates and merge data
vir$tmp <- paste0(vir$x1,"-2020")
vir$date <- as.Date(vir$tmp,format="%d-%b-%Y")
meta$tmp <- paste0(meta$date_month_day,".2020")
meta$date <- as.Date(meta$tmp,format="%m.%d.%Y")
# the meta data has 2 areas:
# Main = underground septic tank (avg = 6.404382)
# T2 = sludge tank (avg = 4.506096) =>
mean(meta$toc_result_mg_l[meta$label=="Main"],na.rm=T)
mean(meta$toc_result_mg_l[meta$label=="T 2"],na.rm=T)
# the virology data has n1 to n3 for the underground septic tank
# and n1_1 to n3_1 for the sludge
mean(vir$n1_1,na.rm=T)
# link the meta data to the virology data
tmp <- meta %>% filter(label=="Main") %>% select(date,toc_result_mg_l,p_h,turbidity_ntu,conductivity)
dat <- left_join(vir %>% select(n1,n2,n3,x5,n1_1,n2_1,n3_1,jeddah,admission,cumulative,date),tmp,by = c("date"))
dat <- dat[!is.na(dat$date),]
# plots
ggplot(dat,aes(x=date,y=cumulative)) + geom_line()
ggplot(dat,aes(x=log(n1),y=p_h)) + geom_point()
ggplot(dat,aes(x=log(n1),y=admission)) + geom_point()
ggplot(dat,aes(x=log(n1))) + geom_histogram()
ggplot(dat,aes(x=log(n2),y=cumulative)) + geom_point()
ggplot(dat,aes(x=log(n2),y=admission)) + geom_point()
ggplot(dat,aes(x=log(n3),y=admission)) + geom_point()
ggplot(dat,aes(x=toc_result_mg_l,y=log(n1),)) + geom_point() + geom_smooth(method="lm")# small positive correlation
# n1
m1 <- lm(log(n1) ~ cumulative + toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summary(m1)
m1 <- lm(log(n1) ~  toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summary(m1)
library(jtools)
# use library(jtools) to get nice CIs
install.packages("jtools")
library(jtools)
# n1
m1 <- lm(log(n1) ~ cumulative + toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summary(m1)
summ(m1, confint = TRUE, digits = 3)
tmp <- summ(m1, confint = TRUE, digits = 3)
tmp$coeftable
tmp <- summ(m1, confint = TRUE, digits = 1)
tmp$coeftable
summ(m1, confint = TRUE, digits = 1)
summ(m1, confint = TRUE, digits = 2)
m2 <- lm(log(n1) ~  toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summ(m2, confint = TRUE, digits = 1)
summ(m2, confint = TRUE, digits = 2)
anova(m1,m2)
# n2
m1 <- lm(log(n2) ~ cumulative + toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
#summary(m1)
summ(m1, confint = TRUE, digits = 2)
# n2
m1 <- lm(log(n2) ~ cumulative + toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
#summary(m1)
summ(m1, confint = TRUE, digits = 2)
m2 <- lm(log(n2) ~ toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summ(m2, confint = TRUE, digits = 2)
anova(m1,m2)
# n3
m1 <- lm(log(n3) ~ cumulative + toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summ(m1, confint = TRUE, digits = 2)
m2 <- lm(log(n3) ~ toc_result_mg_l + p_h + turbidity_ntu + conductivity,data=dat)
summ(m2, confint = TRUE, digits = 2)
anova(m1,m2)
10^(7.98)
setwd("~/Documents/GitHub/jupyter-notebook-shds/Practicals/Datasets/Nutrition")
