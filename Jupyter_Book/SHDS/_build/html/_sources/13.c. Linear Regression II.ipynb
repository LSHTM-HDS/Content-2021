{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 The multivariable linear regression model \n",
    "\n",
    "Suppose we wish to relate an outcome ($Y$) to $p$ predictor variables $(X_1, X_2, ..., X_p)$. The appropriate multivariable linear regression model is a straightforward extension of the simple linear regression model: \n",
    "\n",
    "$$ \n",
    "y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ,..., \\beta_p x_{ip}+\\epsilon_i \\text{ with } \\epsilon_i \\sim NID(0,\\sigma^2).\n",
    "$$ \n",
    "\n",
    "where, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_i &= \\text{value of the dependent variable for the ith participant}\\\\\n",
    "x_{ji} &= \\text{value of the jth predictor variable for the ith participant}. \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The parameters in the model are interpreted as follows:\n",
    "\n",
    "+ $\\beta_0$ is the intercept. It is the expectation of $Y$ when all the $X_j's$ are zero.\n",
    "+ $\\beta_j$ is the expected change in $Y$ for a 1 unit increase in $X_j$ *with all the other covariates held constant*. \n",
    "\n",
    "The $\\beta_j's$ are the **regression coefficients** (otherwise known as **partial regression coefficients**). Each one measures the effect of one covariate controlled (or adjusted) for all of the others. \n",
    "\n",
    "### 13.2.1 The multivariable linear regression model in matrix notation\n",
    "\n",
    "Similarly to the simple linear regression model, the multivariable linear regression model can be expressed using matrix algebra. \n",
    "\n",
    "$$\n",
    "\\mathbf{Y}=\\mathbf{X}\\mathbf{\\beta}+\\mathbf{\\epsilon} \\text{ where }\\epsilon \\sim N(0,\\mathbf{I}\\sigma^2)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}y_1\\\\y_2 \\\\. \\\\. \\\\. \\\\y_n \\end{vmatrix}=\\begin{vmatrix}1 & x_{11} & x_{12} & ... & x_{1p} \\\\ 1 & x_{21} & x_{22} & ... & x_{2p}  \\\\1 & . \\\\1 & .  \\\\ 1& . \\\\1 & x_{p1} & x_{p} & ... & x_{pn} \\end{vmatrix}\\begin{vmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ ... \\\\ \\beta_p \\end{vmatrix}+\\begin{vmatrix}\\epsilon_1\\\\ \\epsilon_2 \\\\ . \\\\ . \\\\. \\\\ \\epsilon_n \\end{vmatrix} \n",
    "$$\n",
    "\n",
    "In this formulation, $\\mathbf{X}$ is an $n \\times (p+1)$ matrix, $Y$ and $\\epsilon$ are vectors of length $n$ whilst $\\mathbf{\\beta}$ is a vector of length $(p+1)$.\n",
    " \n",
    "### 13.2.2 Estimation of the parameters\n",
    "\n",
    "The regression coefficients in multivariable linear regression can be estimated by minimising the residual sum of squares: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "SS_{RES} &= \\sum_{i=1}^n \\hat{\\epsilon}_i^2 = \\sum_{i=1}^n (y_i-\\hat{y})^2 \\\\\n",
    "&= \\sum_{i=1}^n (y_i-\\hat{\\beta}_0-\\hat{\\beta}_1x_{1i}-...-\\hat{\\beta}_px_{pi})^2 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The closed form solution, obtained by solving the $(p+1)$ simultaneous equations that result from setting the partial derivatives of the above equation with respect to each parameter estimate to zero, can be written succinctly using matrix notation: \n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\beta}}= (\\mathbf{X'X})^{-1}X'Y\n",
    "$$\n",
    "\n",
    "$\\mathbf{\\hat{\\beta}}$ is an unbiased estimator of $\\mathbf{\\beta}$. Its distribution is as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{\\hat{\\beta}} \\sim \\mathbf{N(\\beta, (X'X)^{-1}\\sigma^2)}.\n",
    "$$\n",
    "\n",
    "This expresses the fact that the elements of $\\mathbf{\\hat{\\beta}}$ follow a multivariate normal distribution whose variances and covariances are given by $\\mathbf{(X'X)^{-1}\\sigma^2}$. \n",
    "\n",
    "It can also be shown that the following is an unbiased estimator for $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\sigma}^2 &= \\sum_{i=1}^n \\frac{\\hat{\\epsilon_i}^2}{(n-(p+1))}\\\\\n",
    "              &=\\sum_{i=1}^n (y_i - \\hat{\\beta_0} - \\hat{\\beta}_1x_{1i}- ... - \\hat{\\beta_p}x_{ip})^2/(n-(p+1))\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "While it is useful to know how these parameters are estimated, in practice they are often obtained using statistical software. Next, we demonstrate how to perform multivariable regression in R using the birthweight data and discuss the interpretation of the estimated regression coefficients. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
