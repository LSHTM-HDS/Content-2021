
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>14.10 Diagnosis for the logistic regression &#8212; Statistics for Health Data Science</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="14.11 Adequacy of the logistic regression model" href="14.l.%20Logistic%20Regression.html" />
    <link rel="prev" title="14.9 Example 3: Dementia" href="14.j.%20Logistic%20Regression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Statistics for Health Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00.%20Welcome.html">
   Welcome to Statistics for Health Data Science
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Preamble
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00.%20Acknowledgements.html">
   Acknowledgements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="00.%20How_to_use.html">
   How to use this book
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01.%20Introduction.html">
   1 Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Basic probability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="02.%20Probability.Intro.html">
   Probability and statistics
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="02.a.%20Probability.Discrete.html">
   2. Discrete Distributions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="02.b.%20Probability.Discrete.html">
     Bayes' Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02.c.%20Probability.Discrete.html">
     The binomial distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02.d.%20Probability.Discrete.html">
     The Poisson distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02.e.%20Probability.Discrete.html">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="03.a.%20Continuous%20Probability%20Distributions.html">
   3. Continuous distributions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="03.b.%20Continuous%20Probability%20Distributions.html">
     3.1 Continuous random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.c.%20Continuous%20Probability%20Distributions.html">
     3.2 Useful continuous distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.d.%20Continuous%20Probability%20Distributions.html">
     3.3 Uses of the standard Normal distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.e.%20Continuous%20Probability%20Distributions.html">
     3.5 Are the data normally distributed?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.f.%20Continuous%20Probability%20Distributions.html">
     3.5 Joint distributions and correlations
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistical Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="04.%20Inference.Intro.html">
   Statistical Inference
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="04.a.%20Population.and.samples.html">
   4. Populations and Samples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="04.b.%20Population.and.samples.html">
     4.1 Sampling from a population
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.c.%20Population.and.samples.html">
     4.2 Statistical models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.d.%20Population.and.samples.html">
     4.3 Sampling distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.e.%20Population.and.samples.html">
     4.4 Obtaining the sampling distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.f.%20Population.and.samples.html">
     4.5 Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.g.%20Population.and.samples.html">
     Appendix: additional reading
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="05.a.%20Likelihood.html">
   5. Likelihood
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="05.b.%20Likelihood.html">
     5.1 Maximum likelihood estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.c.%20Likelihood.html">
     5.2 The likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.d.%20Likelihood.html">
     5.3 Log likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.e.%20Likelihood.html">
     5.4 Finding the MLE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.f.%20Likelihood.html">
     5.5 Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="06.a.%20Maximum%20Likelihood.html">
   6. Maximum Likelihood
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="06.b.%20Maximum%20Likelihood.html">
     6.1 Likelihood with independent observations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06.c.%20Maximum%20Likelihood.html">
     6.2 Properties of maximum likelihood estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06.d.%20Maximum%20Likelihood.html">
     6.3 Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06.e.%20Maximum%20Likelihood.html">
     Appendix: Additional Reading
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="07.a.%20Frequentist%20I.html">
   7. Frequentist I: Confidence Intervals
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="07.b.%20Frequentist%20I.html">
     7.1 Confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.c.%20Frequentist%20I.html">
     7.2 95% confidence intervals for the mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.d.%20Frequentist%20I.html">
     7.3 Interpretation of confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.e.%20Frequentist%20I.html">
     7.4 Approximate confidence intervals for parameters estimated using large samples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.f.%20Frequentist%20I.html">
     7.5 Confidence Intervals using resampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.g.%20Frequentist%20I.html">
     7.6 Summary: Use of confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.h.%20Frequentist%20I.html">
     Further resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="08.a.%20Frequentist%20II.html">
   8. Frequentist II: Hypothesis tests
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="08.b.%20Frequentist%20II.html">
     8.1 Proving and disproving hypotheses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.c.%20Frequentist%20II.html">
     8.2 The p-value
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.d.%20Frequentist%20II.html">
     8.3 Connection between p-values and confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.e.%20Frequentist%20II.html">
     8.4 Other (mis-)interpretations of p-values
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.f.%20Frequentist%20II.html">
     8.5 Calculating p-values
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.g.%20Frequentist%20II.html">
     Further resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="09.a.%20Bayesian%20Statistics%20I.html">
   9. Bayesian Statistics I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="09.b.%20Bayesian%20Statistics%20I.html">
     Part 1: 9.1 Introduction to Bayesian Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.c.%20Bayesian%20Statistics%20I.html">
     9.2 Bayes Theorem (recap)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.d.%20Bayesian%20Statistics%20I.html">
     9.3 The Bayesian paradigm in Health data science problems.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.e.%20Bayesian%20Statistics%20I.html">
     Part 2:  9.4 Bayes thorem for discrete and continous data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.f.%20Bayesian%20Statistics%20I.html">
     9.5 Bayesian inference on proportions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.g.%20Bayesian%20Statistics%20I.html">
     9.6 Summarising Posteriors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.h.%20Bayesian%20Statistics%20I.html">
     9.7 Prior Predictions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="09.i.%20Bayesian%20Statistics%20I.html">
     9.8 Conjugacy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="10.a.%20Bayesian%20Statistics%20II.html">
   10. Bayesian Statistics II: Normal data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="10.b.%20Bayesian%20Statistics%20II.html">
     10.1 Example: CD4 cell counts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.c.%20Bayesian%20Statistics%20II.html">
     Calculating the posterior
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.d.%20Bayesian%20Statistics%20II.html">
     10.3 Credible Intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.e.%20Bayesian%20Statistics%20II.html">
     10.4 Predictions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.f.%20Bayesian%20Statistics%20II.html">
     10.5 Multiparameter models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="10.g.%20Bayesian%20Statistics%20II.html">
     Further Resources
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistical modelling
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="11.a.%20Types%20of%20Investigation.html">
   11. Types of Investigation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="11.b.%20Types%20of%20Investigation.html">
     11.1 Specifying research questions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11.c.%20Types%20of%20Investigation.html">
     11.2 Different types of investigation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11.d.%20Types%20of%20Investigation.html">
     11.3 Properties of different types of investigation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11.e.%20Types%20of%20Investigation.html">
     11.4 An example: stroke in women
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11.f.%20Types%20of%20Investigation.html">
     11.5 Role of explanatory variables in different types of investigation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11.g.%20Types%20of%20Investigation.html">
     11.6 Example: the role of regression in different types of investigation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="11.h.%20Types%20of%20Investigation.html">
     11.7 Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="12.a.%20Linear%20Regression%20I.html">
   12. Linear Regression I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="12.b.%20Linear%20Regression%20I.html">
     12.1 Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.c.%20Linear%20Regression%20I.html">
     12.2 Simple linear regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.d.%20Linear%20Regression%20I.html">
     12.3 The simple linear regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.e.%20Linear%20Regression%20I.html">
     12.4 Estimation of the population parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.f.%20Linear%20Regression%20I.html">
     12.5 Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.g.%20Linear%20Regression%20I.html">
     12.6 Inference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.h.%20Linear%20Regression%20I.html">
     12.7 Hypothesis testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.i.%20Linear%20Regression%20I.html">
     12.8 Confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.j.%20Linear%20Regression%20I.html">
     12.9 Prediction intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.k.%20Linear%20Regression%20I.html">
     12.10 Multivariable linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.l.%20Linear%20Regression%20I.html">
     12.11 The multivariable linear regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.m.%20Linear%20Regression%20I.html">
     12.12 Birthweight data: Model 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.n.%20Linear%20Regression%20I.html">
     12.13 Centering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.o.%20Linear%20Regression%20I.html">
     12.14 Including categorical predictor variables in linear regression models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.p.%20Linear%20Regression%20I.html">
     12.15 Birthweight data: Model 4
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.q.%20Linear%20Regression%20I.html">
     12.16 Analysis of Variance
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.r.%20Linear%20Regression%20I.html">
     12.17 ANOVA for multivariable linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.s.%20Linear%20Regression%20I.html">
     12.18 ANOVA for models with categorical independent variables.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.t.%20Linear%20Regression%20I.html">
     12.19 Summary of chapter
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="12.u.%20Linear%20Regression%20I.html">
     12.20 Proofs
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="13.a.%20Linear%20Regression%20II.html">
   13. Linear Regression II
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="13.b.%20Linear%20Regression%20II.html">
     13.1 Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.c.%20Linear%20Regression%20II.html">
     13.2 Diagnostics for checking the assumptions of linear regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.d.%20Linear%20Regression%20II.html">
     13.3 Statistical tests of assumptions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.e.%20Linear%20Regression%20II.html">
     13.4 Dealing with violations of assumptions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.f.%20Linear%20Regression%20II.html">
     13.5 Including higher-order terms and interaction terms in a linear regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.g.%20Linear%20Regression%20II.html">
     13.6 Modelling interaction terms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.h.%20Linear%20Regression%20II.html">
     13.7 Interaction between a continuous variable and a binary variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.i.%20Linear%20Regression%20II.html">
     13.8 Interaction between two binary variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.j.%20Linear%20Regression%20II.html">
     13.9 Interaction between two continuous predictor variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.k.%20Linear%20Regression%20II.html">
     13.10 Collinearity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.l.%20Linear%20Regression%20II.html">
     13.11 Different types of investigation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.m.%20Linear%20Regression%20II.html">
     13.12 Example using the birthweight data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="13.n.%20Linear%20Regression%20II.html">
     13.13 Summary of chapter
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="14.a.%20Logistic%20Regression.html">
   14 Logistic Regression
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="14.b.%20Logistic%20Regression.html">
     14.1 Introduction: linear vs. logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.c.%20Logistic%20Regression.html">
     14.2 The dementia dataset
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.d.%20Logistic%20Regression.html">
     14.3 The logistic regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.e.%20Logistic%20Regression.html">
     14.4 Interpretation of the parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.f.%20Logistic%20Regression.html">
     14.5 Example 1: Dementia
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.g.%20Logistic%20Regression.html">
     14.6 Interpretation when
     <span class="math notranslate nohighlight">
      \(X_i\)
     </span>
     is a continuous variable
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.h.%20Logistic%20Regression.html">
     14.7 Example 2: Dementia
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.i.%20Logistic%20Regression.html">
     14.8 Interactions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.j.%20Logistic%20Regression.html">
     14.9 Example 3: Dementia
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     14.10 Diagnosis for the logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.l.%20Logistic%20Regression.html">
     14.11 Adequacy of the logistic regression model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.m.%20Logistic%20Regression.html">
     14.12 Common pitfalls
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="14.n.%20Logistic%20Regression.html">
     14.13 Additional notes
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="15.a.%20Poisson%20Regression%20Model.html">
   15. Generalised Linear Models: Poisson Regression for Count Variables
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="15.b.%20Poisson%20Regression%20Model.html">
     15.1 Introduction to Count Data and Poisson Distribution:
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15.c.%20Poisson%20Regression%20Model.html">
     15.2 Introduction to Poisson generalised linear modelling (Poisson Regression)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15.d.%20Poisson%20Regression%20Model.html">
     15.3 Poisson regression in health data science
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15.e.%20Poisson%20Regression%20Model.html">
     15.4 How to fit a Poisson Regression in R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="15.f.%20Poisson%20Regression%20Model.html">
     15.5 Zero Inflated Poisson Regression Example
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/14.k. Logistic Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https//github.com//LSHTM-HDS//Content-2021"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https//github.com//LSHTM-HDS//Content-2021/issues/new?title=Issue%20on%20page%20%2F14.k. Logistic Regression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh//LSHTM-HDS/main?urlpath=tree/Jupyter_Book/SHDS/14.k. Logistic Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#goodness-of-fit">
   14.10.1 Goodness-of-fit
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mcfadden-pseudo-r-2">
     14.10.1.1 McFadden pseudo-
     <span class="math notranslate nohighlight">
      \(R^2\)
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-hosmer-lemeshow-test">
     14.10.1.2 The Hosmer-Lemeshow test
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#predictive-performance">
   14.10.2 Predictive performance
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predictions">
     14.10.2.1 Predictions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#calibration">
     14.10.2.2 Calibration
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sensitivity-and-specificity">
     14.10.2.3 Sensitivity and Specificity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-receiving-operator-characteristic-roc-curve">
     14.10.2.4 The
     <em>
      receiving operator characteristic
     </em>
     (ROC) curve
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#external-validation">
     14.10.2.5 External validation
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="diagnosis-for-the-logistic-regression">
<h1>14.10 Diagnosis for the logistic regression<a class="headerlink" href="#diagnosis-for-the-logistic-regression" title="Permalink to this headline">¶</a></h1>
<p>When using a regression model, and in particular a logistic regression model, it is important to bear in mind the goal of the study. To simplify, it can be either a predictive goal or an explanatory goal. If the goal is to have a model with very good predictive ability, we do not really care about which variables are included in the model as long as its predictive abilities are good. When selecting the model, we will prefer a model with good predictive value on external data even at the price of a lesser good fit to the initial dataset. However, let us note that there is often a correlation between a model that fits corretly the initial data and a model with good predictive ability. If the goal is explanatory, we focus on the clinical validity of the model and the interpretation of the parameters. Thus, which variables are included into the model should be carefully thought using scientific knowledge of the modelisation problem from clinician inputs. Also, when selecting the model, we will prefer a model that carefully takes into account the relation between the variables from the study data rather than a model that have good predictive ability on an external dataset. However, we expect from a good model estimated from appropriate data that similar results shall be found on an appropriate external dataset. This is a topic of major interest in science and is known as the <em>reproducibility of scientific research</em>. Finally, let us also note that the goal of a study can also be to explore the causal structure between some variables and the outcome rather than just associations. However, causality and causal inference will not be mentioned in this lecture.</p>
<p>We will first see how to evaluate the explanatory abilities of a logistic regression model using goodness-of-fit tools that evaluates how close to the data the model actually is and then we will see how to evaluate the predictive abilities of a logistic regression model.</p>
<div class="section" id="goodness-of-fit">
<h2>14.10.1 Goodness-of-fit<a class="headerlink" href="#goodness-of-fit" title="Permalink to this headline">¶</a></h2>
<p>We have already seen some concepts used to assess the goodness-of-fit of regression model: the deviance, which measures the distance between the model and the saturated model and the AIC that penalizes over-fitting. We present here two additional way of assessing the goodness-of-fit of the logistic regression model.</p>
<div class="section" id="mcfadden-pseudo-r-2">
<h3>14.10.1.1 McFadden pseudo-<span class="math notranslate nohighlight">\(R^2\)</span><a class="headerlink" href="#mcfadden-pseudo-r-2" title="Permalink to this headline">¶</a></h3>
<p>For the linear regression model, we have studied the <span class="math notranslate nohighlight">\(R^2\)</span> that measures how much variability is explained by the model. For the logistic regression model, several generalization of the <span class="math notranslate nohighlight">\(R^2\)</span> measure have been proposed. Here, we will focus on the McFadden’s pseudo-<span class="math notranslate nohighlight">\(R^2\)</span>. The McFadden <span class="math notranslate nohighlight">\(R^2\)</span> is defined as follow:</p>
<div class="math notranslate nohighlight">
\[R^2_{McFadden} = 1 - \frac{\ell_e}{\ell_0}\]</div>
<p>where <span class="math notranslate nohighlight">\(\ell_e\)</span> is the log-likelihood of the estimated model and <span class="math notranslate nohighlight">\(\ell_0\)</span> is the log-likelihood of the null model having only an intercept. The rationale behind this measure is that, when the estimated model does not explain correctly the variability, its log-likelihood will be close to the null log-likelihood so that the ratio will be close to <span class="math notranslate nohighlight">\(1\)</span> and the McFadden’s pseudo-<span class="math notranslate nohighlight">\(R^2\)</span> close to <span class="math notranslate nohighlight">\(0\)</span>. On the contrary, when the model correctly explains the variability of the model, the likelihood will be close to <span class="math notranslate nohighlight">\(1\)</span> and therefore <span class="math notranslate nohighlight">\(\ell_e\)</span> will be close to <span class="math notranslate nohighlight">\(0\)</span> so that the McFadden’s pseudo-<span class="math notranslate nohighlight">\(R^2\)</span> will be close to <span class="math notranslate nohighlight">\(1\)</span>. However, when applied to a classic linear regression model, the McFadden’s pseudo-<span class="math notranslate nohighlight">\(R^2\)</span> is not equivalent to the classic <span class="math notranslate nohighlight">\(R_2\)</span>.</p>
<p>It is possible to compute the McFadden’s pseudo-<span class="math notranslate nohighlight">\(R^2\)</span> from <code class="docutils literal notranslate"><span class="pre">R</span></code> quite easily using the function <code class="docutils literal notranslate"><span class="pre">logLik</span></code> that extracts the value of the estimated log-likelihood for a <code class="docutils literal notranslate"><span class="pre">glm</span></code> object. If we want to compute it for our three examples, this is how we would do</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># first we estimate the null model</span>
<span class="n">dementia0</span> <span class="o">&lt;-</span> <span class="nf">glm</span><span class="p">(</span><span class="n">dementia</span> <span class="o">~</span> <span class="m">1</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dementia</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="nf">binomial</span><span class="p">(</span><span class="n">link</span><span class="o">=</span><span class="s">&quot;logit&quot;</span><span class="p">))</span> 

<span class="c1"># then we compute the McFadden pseudo-R2 for each model</span>
<span class="n">R2_McFadden1</span> <span class="o">&lt;-</span> <span class="nf">as.double</span><span class="p">(</span><span class="m">1</span> <span class="o">-</span> <span class="nf">logLik</span><span class="p">(</span><span class="n">dementia1</span><span class="p">)</span><span class="o">/</span><span class="nf">logLik</span><span class="p">(</span><span class="n">dementia0</span><span class="p">))</span>
<span class="n">R2_McFadden2</span> <span class="o">&lt;-</span> <span class="nf">as.double</span><span class="p">(</span><span class="m">1</span> <span class="o">-</span> <span class="nf">logLik</span><span class="p">(</span><span class="n">dementia2</span><span class="p">)</span><span class="o">/</span><span class="nf">logLik</span><span class="p">(</span><span class="n">dementia0</span><span class="p">))</span>
<span class="n">R2_McFadden3</span> <span class="o">&lt;-</span> <span class="nf">as.double</span><span class="p">(</span><span class="m">1</span> <span class="o">-</span> <span class="nf">logLik</span><span class="p">(</span><span class="n">dementia3</span><span class="p">)</span><span class="o">/</span><span class="nf">logLik</span><span class="p">(</span><span class="n">dementia0</span><span class="p">))</span>

<span class="nf">round</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;model 1&quot;</span> <span class="o">=</span> <span class="n">R2_McFadden1</span><span class="p">,</span> <span class="s">&quot;model 2&quot;</span> <span class="o">=</span> <span class="n">R2_McFadden2</span><span class="p">,</span> <span class="s">&quot;model 3&quot;</span> <span class="o">=</span> <span class="n">R2_McFadden3</span><span class="p">),</span><span class="m">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">Error</span> <span class="ow">in</span> <span class="ow">is</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">data</span><span class="p">):</span> <span class="nb">object</span> <span class="s1">&#39;dementia&#39;</span> <span class="ow">not</span> <span class="n">found</span>
<span class="ne">Traceback</span>:

<span class="mi">1</span><span class="o">.</span> <span class="n">glm</span><span class="p">(</span><span class="n">dementia</span> <span class="o">~</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dementia</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">binomial</span><span class="p">(</span><span class="n">link</span> <span class="o">=</span> <span class="s2">&quot;logit&quot;</span><span class="p">))</span>
<span class="mi">2</span><span class="o">.</span> <span class="nb">eval</span><span class="p">(</span><span class="n">mf</span><span class="p">,</span> <span class="n">parent</span><span class="o">.</span><span class="n">frame</span><span class="p">())</span>
<span class="mi">3</span><span class="o">.</span> <span class="nb">eval</span><span class="p">(</span><span class="n">mf</span><span class="p">,</span> <span class="n">parent</span><span class="o">.</span><span class="n">frame</span><span class="p">())</span>
<span class="mi">4</span><span class="o">.</span> <span class="n">stats</span><span class="p">::</span><span class="n">model</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="n">dementia</span> <span class="o">~</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dementia</span><span class="p">,</span> <span class="n">drop</span><span class="o">.</span><span class="n">unused</span><span class="o">.</span><span class="n">levels</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">)</span>
<span class="mi">5</span><span class="o">.</span> <span class="n">model</span><span class="o">.</span><span class="n">frame</span><span class="o">.</span><span class="n">default</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="n">dementia</span> <span class="o">~</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dementia</span><span class="p">,</span> 
 <span class="o">.</span>     <span class="n">drop</span><span class="o">.</span><span class="n">unused</span><span class="o">.</span><span class="n">levels</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">)</span>
<span class="mi">6</span><span class="o">.</span> <span class="ow">is</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can see that the second model which included three different variables is the one with the highest ability to explain the variability from the data. The first one performed poorly as it included only one binary variable and the third model also perform quite poorly even though we included an interaction between <span class="math notranslate nohighlight">\(bmi_i\)</span> and <span class="math notranslate nohighlight">\(sex_i\)</span>.</p>
</div>
<div class="section" id="the-hosmer-lemeshow-test">
<h3>14.10.1.2 The Hosmer-Lemeshow test<a class="headerlink" href="#the-hosmer-lemeshow-test" title="Permalink to this headline">¶</a></h3>
<p>The Hosmer-Lemeshow test (ref) is a classic approach to assess the goodness-of-fit of a logistic regression model. The rationale of this test is to divide the vector of predicted probabilites <span class="math notranslate nohighlight">\(\hat{\pi} = (\hat{\pi}_i)\)</span> with <span class="math notranslate nohighlight">\(i=1,\dots,n\)</span> into <span class="math notranslate nohighlight">\(G\)</span> groups, e.g. based on the quantiles, with <span class="math notranslate nohighlight">\(n_g\)</span> subjects. In each group, the mean of the predicted probabilites <span class="math notranslate nohighlight">\(\bar{\pi}_g\)</span> is compared to the proportion of observed success. Formally, for the group <span class="math notranslate nohighlight">\(g=1,\dots,G\)</span>, we have that</p>
<ul class="simple">
<li><p>the observed values are</p>
<ul>
<li><p>for Y = 1: <span class="math notranslate nohighlight">\(y_g\)</span></p></li>
<li><p>for Y = 0: <span class="math notranslate nohighlight">\(n_g - y_g\)</span></p></li>
</ul>
</li>
<li><p>the predicted values are</p>
<ul>
<li><p>for Y = 1: <span class="math notranslate nohighlight">\(\bar{\pi}_gn_g\)</span></p></li>
<li><p>for Y = 0: <span class="math notranslate nohighlight">\(n_g(1 - \bar{\pi}_g)\)</span></p></li>
</ul>
</li>
</ul>
<p>The Hosmer-Lemeshow test statistics is based on the chi-square statistics computed over all groups and all possible values for <span class="math notranslate nohighlight">\(Y\)</span></p>
<div class="math notranslate nohighlight">
\[\sum_{g=1}^G\sum_{l=0}^1 \frac{(o_{gl} - e_{gl})^2}{e_{gl}} = \sum_{g=1}^G \frac{(n_g\bar{\pi}_g - y_g)^2}{n_g\bar{\pi}_g(1-\bar{\pi}_g)}\]</div>
<p>and has been shown to follow asymptotically a <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution with <span class="math notranslate nohighlight">\(g-2\)</span> degrees of freedom under the null hypothesis of a correctly specified model. However, we insist on the fact that this test if often criticized for several reasons. First it is known to have low power. Secondly, its results can be sensible to the choice of the number of groups <span class="math notranslate nohighlight">\(G\)</span> and this is even worst for small sample sizes.</p>
<p>The Hesmer-Lemeshow test statistics has not been implemented into the <code class="docutils literal notranslate"><span class="pre">glm</span></code> package but is available on the <code class="docutils literal notranslate"><span class="pre">ResourceSelection</span></code> package through the <code class="docutils literal notranslate"><span class="pre">hoslem.test</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">ResourceSelection</span><span class="p">,</span> <span class="n">quietly</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">Error</span> <span class="ow">in</span> <span class="n">library</span><span class="p">(</span><span class="n">ResourceSelection</span><span class="p">,</span> <span class="n">quietly</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">):</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">no</span> <span class="n">package</span> <span class="n">called</span> <span class="s1">&#39;ResourceSelection&#39;</span>
<span class="ne">Traceback</span>:

<span class="mi">1</span><span class="o">.</span> <span class="n">library</span><span class="p">(</span><span class="n">ResourceSelection</span><span class="p">,</span> <span class="n">quietly</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can make the test for different values of <span class="math notranslate nohighlight">\(g\)</span>, for example for <span class="math notranslate nohighlight">\(g\)</span> ranging from <span class="math notranslate nohighlight">\(5\)</span> to <span class="math notranslate nohighlight">\(15\)</span> and, for each, print the associated p-value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">for </span><span class="p">(</span><span class="n">g</span> <span class="n">in</span> <span class="m">5</span><span class="o">:</span><span class="m">15</span><span class="p">)</span> <span class="p">{</span>
	<span class="nf">print</span><span class="p">(</span><span class="nf">hoslem.test</span><span class="p">(</span><span class="n">dementia2</span><span class="o">$</span><span class="n">y</span><span class="p">,</span> <span class="nf">fitted</span><span class="p">(</span><span class="n">dementia2</span><span class="p">),</span> <span class="n">g</span><span class="o">=</span><span class="n">g</span><span class="p">)</span><span class="o">$</span><span class="n">p.value</span><span class="p">)</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>Error in hoslem.test(dementia2$y, fitted(dementia2), g = g): could not find function &quot;hoslem.test&quot;
Traceback:

1. print(hoslem.test(dementia2$y, fitted(dementia2), g = g)$p.value)
</pre></div>
</div>
</div>
</div>
<p>We can see that indeed, the p-value are very dependent upon the value of <span class="math notranslate nohighlight">\(g\)</span> which makes this test not very appropriate to test for the goodness-of-fit of the model. However, here, all the p-values are over <span class="math notranslate nohighlight">\(0.05\)</span> and therefore we do not reject the null hypothesis of a correctly specified model.</p>
<blockquote>
<div><p><em>Hosmer, D. W., Lemeshow, S. (1980) Goodness of fit tests for the multiple logistic regression model. Communications in Statistics – Theory and Methods</em></p>
</div></blockquote>
<blockquote>
<div><p>Hosmer D. W., Lemeshow S. and Rodney X. S. Applied logistic regression. Wiley, 2013.</p>
</div></blockquote>
</div>
</div>
<div class="section" id="predictive-performance">
<h2>14.10.2 Predictive performance<a class="headerlink" href="#predictive-performance" title="Permalink to this headline">¶</a></h2>
<p>The predictive performance of a model evaluates how well the model is able to predict the outcome for given observations. In certain cases, for example when developing diagnosis tools, the predictive performance of a model is essential.</p>
<div class="section" id="predictions">
<h3>14.10.2.1 Predictions<a class="headerlink" href="#predictions" title="Permalink to this headline">¶</a></h3>
<p>When estimating a logistic regression model in <code class="docutils literal notranslate"><span class="pre">R</span></code>, we estimate all the parameters <span class="math notranslate nohighlight">\((\beta_k)\)</span> with <span class="math notranslate nohighlight">\(k=0,\dots,p\)</span>. From these and knowing the observed covariate values <span class="math notranslate nohighlight">\((x_i)\)</span> for each subject <span class="math notranslate nohighlight">\(i=1,\dots,n\)</span>, we could easily compute an estimate of <span class="math notranslate nohighlight">\(\pi_i\)</span> the probability for subject <span class="math notranslate nohighlight">\(i\)</span> of having <span class="math notranslate nohighlight">\(Y_i=1\)</span>. We could do it by hand, but we can also directly use the function <code class="docutils literal notranslate"><span class="pre">predict</span></code> whose goal is to compute the estimated outcome of subjects from given data according to a given estimated model.</p>
<p>With the <code class="docutils literal notranslate"><span class="pre">predict</span></code> function, we can either compute the estimation on the linear predictor scale <span class="math notranslate nohighlight">\(\hat{\beta}^{\top}X\)</span> or on the response scale <span class="math notranslate nohighlight">\(\exp(\hat{\beta}^{\top}X\)</span>)/(1+<span class="math notranslate nohighlight">\(exp(\hat{\beta}^{\top}X))\)</span>. Both are equivalent and the second can be computed from the first by using the inverse of the <span class="math notranslate nohighlight">\(\mathrm{logit}\)</span> function as we have seen when introducing the logistic model. In <code class="docutils literal notranslate"><span class="pre">R</span></code>, the choice is made through the option <code class="docutils literal notranslate"><span class="pre">type</span></code>. By default, the prediction computed is on the linear predictor scale, when the option <code class="docutils literal notranslate"><span class="pre">type=&quot;response&quot;</span></code> is chosen, the prediction will be on the response scale, here in <span class="math notranslate nohighlight">\([0;1]\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dementia2</span><span class="p">,</span> <span class="n">dementia</span><span class="p">)</span>
<span class="n">predicted_resp</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">dementia2</span><span class="p">,</span> <span class="n">dementia</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&quot;response&quot;</span><span class="p">)</span>

<span class="nf">cbind</span><span class="p">(</span><span class="s">&quot;linear predictor&quot;</span> <span class="o">=</span> <span class="nf">head</span><span class="p">(</span><span class="n">predicted</span><span class="p">),</span> <span class="s">&quot;response&quot;</span> <span class="o">=</span> <span class="nf">head</span><span class="p">(</span><span class="n">predicted_resp</span><span class="p">),</span> <span class="s">&quot;response from linear predictor&quot;</span> <span class="o">=</span> <span class="nf">head</span><span class="p">(</span><span class="nf">exp</span><span class="p">(</span><span class="n">predicted</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="m">1</span><span class="o">+</span><span class="p">(</span><span class="nf">exp</span><span class="p">(</span><span class="n">predicted</span><span class="p">)))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">Error</span> <span class="ow">in</span> <span class="n">predict</span><span class="p">(</span><span class="n">dementia2</span><span class="p">,</span> <span class="n">dementia</span><span class="p">):</span> <span class="nb">object</span> <span class="s1">&#39;dementia2&#39;</span> <span class="ow">not</span> <span class="n">found</span>
<span class="ne">Traceback</span>:

<span class="mi">1</span><span class="o">.</span> <span class="n">predict</span><span class="p">(</span><span class="n">dementia2</span><span class="p">,</span> <span class="n">dementia</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="calibration">
<h3>14.10.2.2 Calibration<a class="headerlink" href="#calibration" title="Permalink to this headline">¶</a></h3>
<p>A model is said to be well calibrated if the predicted probabilities match the actual proportion of observed events in strata of the data. Generally, these strata are obtained by dividing the covariate space into a finite number of sets. However, when the covariate are continuous, the number of possible sets becomes large and these strata can become too little. Therefore, one approach is to group subjects according to their predicted probabilities and use these groups as strata, exactly as the Hosmer-Lemeshow test is doing.</p>
</div>
<div class="section" id="sensitivity-and-specificity">
<h3>14.10.2.3 Sensitivity and Specificity<a class="headerlink" href="#sensitivity-and-specificity" title="Permalink to this headline">¶</a></h3>
<p>To compute the estimated outcome <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> from these estimated probabilies, we generally chose a threshold value <span class="math notranslate nohighlight">\(\alpha\)</span> in the interval <span class="math notranslate nohighlight">\(]0,1[\)</span>, and for all subjects with <span class="math notranslate nohighlight">\(\pi_i&lt;=\alpha\)</span>, <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> is fixed at <span class="math notranslate nohighlight">\(0\)</span> while for all subjects with <span class="math notranslate nohighlight">\(\pi_i&gt;\alpha\)</span>, <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> is fixed at <span class="math notranslate nohighlight">\(1\)</span>. To assess the predictive quality of the predictions, the idea is to compare the observed outcomes to the predicted outcomes. To do so, we introduce two notions: <span class="math notranslate nohighlight">\(Se\)</span> the sensitivity and <span class="math notranslate nohighlight">\(Sp\)</span> the specificity that are defined as follows</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
Se &amp;= Pr(\hat{y}_i=1|y_i=1) = \frac{\sum_{i=1}^n 1_{(\hat{\pi}_i&gt;\alpha~\&amp;~ y_i=1~)}}{\sum_{i=1}^n 1_{(y_i=1)}}\\
Sp &amp;= Pr(\hat{y}_i=0|y_i=0) = \frac{\sum_{i=1}^n 1_{(\hat{\pi}_i\leq\alpha~\&amp;~ y_i=0~)}}{\sum_{i=1}^n 1_{(y_i=0)}}
\end{align}\end{split}\]</div>
<p>The sensitivity is the rate of true positives and the specificity is the rate of true negatives. Ideally, we would want to make a prediction <span class="math notranslate nohighlight">\(\hat{y}\)</span> of the outcome <span class="math notranslate nohighlight">\(y\)</span> that gives at the same time high sensitivity and high specificity. The choice of <span class="math notranslate nohighlight">\(\alpha\)</span>, the threshold value, has obviously a great impact on the sensitivity and specificity values. For example, a high <span class="math notranslate nohighlight">\(\alpha\)</span> will generate a high specificity but a low sensitivity while a low <span class="math notranslate nohighlight">\(\alpha\)</span> will do the opposite. The goal is to have an optimal <span class="math notranslate nohighlight">\(\alpha\)</span> that maximize both the sensitivity and specificity.</p>
<blockquote>
<div><p><em>Exercise:</em> Write a code in <code class="docutils literal notranslate"><span class="pre">R</span></code> to compute <span class="math notranslate nohighlight">\(Se\)</span> and <span class="math notranslate nohighlight">\(Sp\)</span> for any value of <span class="math notranslate nohighlight">\(\alpha\)</span></p>
</div></blockquote>
</div>
<div class="section" id="the-receiving-operator-characteristic-roc-curve">
<h3>14.10.2.4 The <em>receiving operator characteristic</em> (ROC) curve<a class="headerlink" href="#the-receiving-operator-characteristic-roc-curve" title="Permalink to this headline">¶</a></h3>
<p>The ROC curve is an intuitive way of plotting the relation between sensitivity and specificity computed for a whole range of values of <span class="math notranslate nohighlight">\(\alpha\)</span> between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>. It plots <span class="math notranslate nohighlight">\(Se\)</span> against <span class="math notranslate nohighlight">\(1-Sp\)</span>. It can directly be plotted in <code class="docutils literal notranslate"><span class="pre">R</span></code> with the function <code class="docutils literal notranslate"><span class="pre">roc</span></code> from the <code class="docutils literal notranslate"><span class="pre">pROC</span></code>package that takes as argument, the actual observed outcomes and the predicted response probabilities from the estimated model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">pROC</span><span class="p">,</span> <span class="n">quietly</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
<span class="nf">plot</span><span class="p">(</span><span class="nf">roc</span><span class="p">(</span><span class="n">response</span> <span class="o">=</span> <span class="n">dementia</span><span class="o">$</span><span class="n">dementia</span><span class="p">,</span> <span class="n">predictor</span> <span class="o">=</span> <span class="n">predicted_resp</span><span class="p">),</span> <span class="n">print.auc</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">Error</span> <span class="ow">in</span> <span class="n">library</span><span class="p">(</span><span class="n">pROC</span><span class="p">,</span> <span class="n">quietly</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">):</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">no</span> <span class="n">package</span> <span class="n">called</span> <span class="s1">&#39;pROC&#39;</span>
<span class="ne">Traceback</span>:

<span class="mi">1</span><span class="o">.</span> <span class="n">library</span><span class="p">(</span><span class="n">pROC</span><span class="p">,</span> <span class="n">quietly</span> <span class="o">=</span> <span class="n">TRUE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A perfect model should have a high sensitivity and a high specificity and its ROC curve shoud attain the top-left corner of the plot. A model without predictive ability shoud lie on the identity curve. The goal is to find a model that gets close to the top-left corner. To assess how close to the top-left corner a ROC curve is, one of the most used measure in the <em>area under the ROC</em>, often shortly referred in the literature as the <em>AUC</em> for <em>area under the curve</em>. The perfect model would have an AUC of <span class="math notranslate nohighlight">\(1\)</span> while a poor model shall have an AUC of <span class="math notranslate nohighlight">\(0.5\)</span>, the goal is to find a model whose AUC gets close to <span class="math notranslate nohighlight">\(1\)</span>, i.e. that has high specificity and high sensitivity.</p>
<p>In our example, we find an AUC of <span class="math notranslate nohighlight">\(0.840\)</span> which is quite good. However, we can expect to achieve better results with a more appropriate model as the example used here remains a very simple model.</p>
<blockquote>
<div><p><em>Exercise:</em> Using the code you have written for computing <span class="math notranslate nohighlight">\(Se\)</span> and <span class="math notranslate nohighlight">\(Sp\)</span>, write a code that plots the ROC curve.</p>
</div></blockquote>
<p>Note that the ROC curve is a very traditional tool from the predictive toolkit but it is less and less used as it is not very informative \emph{per se} reporting directly the numbers is preferred.</p>
</div>
<div class="section" id="external-validation">
<h3>14.10.2.5 External validation<a class="headerlink" href="#external-validation" title="Permalink to this headline">¶</a></h3>
<p>In the example, we have estimated a model on the <code class="docutils literal notranslate"><span class="pre">dementia</span></code> dataset and have studied its prediction ability on the same data. This is not a good approach in general. The issue here is that, by estimating and validating the model on the exact same dataset, we might capture pattern specific to this dataset and the predictive ability of the model might be very different on external data.</p>
<p>A solution to tackle this issue is to use different data to estimate and validate the model in order to avoid overfitting to a particular dataset. The data used to estimate and calibrate the model is called <em>the learning data</em> and the data used to validate the prediction accuracy of the model is called the <em>validation data</em>. There are different ways of applying this idea into practice:</p>
<ul class="simple">
<li><p>we can divide the initial dataset into two parts (not necessarily of equal size): the learning one and the validation one</p></li>
<li><p>the <span class="math notranslate nohighlight">\(k-\)</span>fold cross validation is a resampling technique that divides the initial dataset into <span class="math notranslate nohighlight">\(k\)</span> smaller datasets. Each one of the <span class="math notranslate nohighlight">\(k\)</span> groups will serves as a validation dataset for a model estimated on the other <span class="math notranslate nohighlight">\(k-1\)</span> dataset. By repeating this for the <span class="math notranslate nohighlight">\(k\)</span> small datasets separately, we obtain <span class="math notranslate nohighlight">\(k\)</span> different predictions from which we can evaluate the goodness-of-fit of the model. When <span class="math notranslate nohighlight">\(k=1\)</span>, this method is known as the <em>leave-one-out</em> procedure</p></li>
<li><p>the <em>bootstrap</em> procedure is a reseampling technique that artificially creates several dataset from the same initial dataset by resampling subjects with replacement</p></li>
<li><p>use an external dataset from a different source as validation data for the model estimated from an initial dataset</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            kernelName: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="14.j.%20Logistic%20Regression.html" title="previous page">14.9 Example 3: Dementia</a>
    <a class='right-next' id="next-link" href="14.l.%20Logistic%20Regression.html" title="next page">14.11 Adequacy of the logistic regression model</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By MSc Health Data Science, LSHTM<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>