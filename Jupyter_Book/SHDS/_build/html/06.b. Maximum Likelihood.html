
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6.1 Likelihood and log-likelihood with \(n\) independent observations &#8212; Statistics for Health Data Science</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="6.2 Properties of maximum likelihood estimators" href="06.c.%20Maximum%20Likelihood.html" />
    <link rel="prev" title="6. Maximum Likelihood" href="06.a.%20Maximum%20Likelihood.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Statistics for Health Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="00.%20Welcome.html">
   Welcome to Statistics for Health Data Science
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01.%20Introduction.html">
   1 Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Basic probability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="02.a.%20Probability.Discrete.html">
   2. Probability and Discrete Probability Distributions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="02.b.%20Probability.Discrete.html">
     2.1 Bayesâ€™ Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02.c.%20Probability.Discrete.html">
     2.2 The binomial distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02.d.%20Probability.Discrete.html">
     2.3 The Poisson distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="03.a.%20Continuous%20Probability%20Distributions.html">
   3. Continuous probability distributions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="03.b.%20Continuous%20Probability%20Distributions.html">
     3.1 Continuous random variables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.c.%20Continuous%20Probability%20Distributions.html">
     3.2 Useful continuous distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.d.%20Continuous%20Probability%20Distributions.html">
     3.3 Uses of the standard Normal distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.e.%20Continuous%20Probability%20Distributions.html">
     3.5 Are the data normally distributed?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03.f.%20Continuous%20Probability%20Distributions.html">
     3.5 Joint distributions and correlations
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistical Inference
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="04.a.%20Population.and.samples.html">
   4. Populations and Samples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="04.b.%20Population.and.samples.html">
     4.1 Sampling from a population
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.c.%20Population.and.samples.html">
     4.2 Statistical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.d.%20Population.and.samples.html">
     4.3 Sampling distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.e.%20Population.and.samples.html">
     4.4 Obtaining the sampling distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.f.%20Population.and.samples.html">
     4.5 Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04.g.%20Population.and.samples.html">
     Appendix: additional reading
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="05.a.%20Likelihood.html">
   5. Likelihood
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="05.b.%20Likelihood.html">
     5. Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.c.%20Likelihood.html">
     5. Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.d.%20Likelihood.html">
     5. Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.f.%20Likelihood.html">
     5. Likelihood
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05.g.%20Likelihood.html">
     5. Likelihood
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="06.a.%20Maximum%20Likelihood.html">
   6. Maximum Likelihood
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.1 Likelihood and log-likelihood with
     <span class="math notranslate nohighlight">
      \(n\)
     </span>
     independent observations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06.c.%20Maximum%20Likelihood.html">
     6.2 Properties of maximum likelihood estimators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06.d.%20Maximum%20Likelihood.html">
     6.3 Summary
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="06.e.%20Maximum%20Likelihood.html">
     Appendix: Additional Reading
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="07.a.%20Frequentist%20I.html">
   7. Frequentist I: Confidence Intervals (CIs)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="07.b.%20Frequentist%20I.html">
     7.1 Introduction to confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.c.%20Frequentist%20I.html">
     7.2 95% confidence intervals for the mean
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.d.%20Frequentist%20I.html">
     7.3 Interpretation of confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.e.%20Frequentist%20I.html">
     7.4 Approximate confidence intervals for parameters estimated using large samples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.f.%20Frequentist%20I.html">
     7.5 Confidence Intervals using resampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.g.%20Frequentist%20I.html">
     7.6 Summary: Use of confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="07.h.%20Frequentist%20I.html">
     Further resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="08.a.%20Frequentist%20II.html">
   8. Frequentist II: Hypothesis tests
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="08.b.%20Frequentist%20II.html">
     8.1 Proving and disproving hypotheses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.c.%20Frequentist%20II.html">
     8.2 The p-value
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.d.%20Frequentist%20II.html">
     8.3 Connection between p-values and confidence intervals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.e.%20Frequentist%20II.html">
     8.4 Other (mis-)interpretations of p-values
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.f.%20Frequentist%20II.html">
     8.5 Calculating p-values
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="08.g.%20Frequentist%20II.html">
     Further resources
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09.%20Bayesian%20Statistics%20I.html">
   9. Bayesian Statistics I
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10.%20Bayesian%20Statistics%20II.html">
   10. Bayesian Statistics II: Normal data
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistical modelling
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="11.%20Types%20of%20Investigation.html">
   11. Types of Investigation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="12.%20Linear%20Regression%20I.html">
   12. Linear Regression I
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="13.%20Linear%20Regression%20II.html">
   13. Linear Regression II
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="14.%20Logistic%20Regression.html">
   14 Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="15.%20Poisson%20Regression%20Model.html">
   15. Generalised Linear Models: Poisson Regression for Count Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="16.%20Extensions%20Confounding%2C%20standardization%2C%20and%20collapsibility.html">
   16. Extensions: Confounding, standardization, and collapsibility
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/06.b. Maximum Likelihood.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/LSHTM-HDS/Content-2021"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/LSHTM-HDS/Content-2021/issues/new?title=Issue%20on%20page%20%2F06.b. Maximum Likelihood.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/LSHTM-HDS/Content-2021/master?urlpath=tree/docs/06.b. Maximum Likelihood.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   6.1 Likelihood and log-likelihood with
   <span class="math notranslate nohighlight">
    \(n\)
   </span>
   independent observations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-exponential-distribution">
   6.1.1 Example: Exponential distribution
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-normal-distribution">
   6.1.2 Example: Normal distribution
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="likelihood-and-log-likelihood-with-n-independent-observations">
<h1>6.1 Likelihood and log-likelihood with <span class="math notranslate nohighlight">\(n\)</span> independent observations<a class="headerlink" href="#likelihood-and-log-likelihood-with-n-independent-observations" title="Permalink to this headline">Â¶</a></h1>
<p>Suppose that you collect a sample of <span class="math notranslate nohighlight">\(n\)</span> observations. If the <span class="math notranslate nohighlight">\(n\)</span> observations are independent, then the joint likelihood function from these <span class="math notranslate nohighlight">\(n\)</span> observations has a very convenient form; it is the product of the likelihood from each observation. If <span class="math notranslate nohighlight">\(X_1,..., X_n\)</span> are i.i.d., and we observe a sample <span class="math notranslate nohighlight">\(\mathbf{x} = \left\{ x_1, x_2, ..., x_n \right\}\)</span>:</p>
<p>\begin{align*}
L \left( \theta \mid \mathbf{x} \right) &amp;=  L\left( \theta \mid x_1 \right) L\left( \theta \mid x_2 \right) â€¦  L \left( \theta \mid x_n \right) \
&amp;= \prod_{i=1}^n  L\left( \theta \mid x_i \right)
\end{align*}.</p>
<p>Recall that we often prefer to work with the log-likelihood function, as it simplifies the algebra when it comes to finding the MLE. The log-likelihood function for <span class="math notranslate nohighlight">\(n\)</span> independent observations is:
\begin{align*}
l \left( \theta \mid \mathbf{x} \right)
&amp;= log \prod_{i=1}^n L\left( \theta \mid x_i \right) \
&amp;= \sum_{i=1}^n log L\left( \theta \mid x_i \right) \
&amp;= \sum_{i=1}^n l\left( \theta \mid x_i \right) \
\end{align*}</p>
<p>Finding the MLE involves the same three steps as we saw in Session 5, but the log-likelihood function is now a joint function for the <span class="math notranslate nohighlight">\(n\)</span> observations:</p>
<div class="alert alert-success">
<p><b> Method for finding MLEs:</b></p>
<ol class="simple">
<li><p>Obtain the derivative of the log-likelihood: <span class="math notranslate nohighlight">\(\frac{d l(\theta \mid \mathbf{x})}{d \theta}\)</span></p></li>
<li><p>Set <span class="math notranslate nohighlight">\(\frac{d l(\theta \mid \mathbf{x})}{d \theta}=0\)</span> and solve for <span class="math notranslate nohighlight">\(\theta\)</span></p></li>
<li><p>Verify that it is a maximum by showing that the second derivative <span class="math notranslate nohighlight">\(\frac{d ^2 l(\theta \mid  \mathbf{x})}{d \theta ^2 }\)</span> is negative when the MLE is substituted for <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
</ol>
</div>
</div>
<div class="section" id="example-exponential-distribution">
<h1>6.1.1 Example: Exponential distribution<a class="headerlink" href="#example-exponential-distribution" title="Permalink to this headline">Â¶</a></h1>
<p>Recall the example from Session 5 on the time that patients wait until their GP appointment in a particular practice. The receptionist records the time that elapses between when a patient walks through the door, and when they are called through for their appointment for a random sample of eight people. These times (in minutes) are: 8.75, 10.20, 15.29, 7.89, 7.04, 12.04, 19.04, 17.50.</p>
<p>As a reminder, we can model the waiting time until a specific event using the exponential distribution with parameter <span class="math notranslate nohighlight">\(\lambda\)</span>, which has a probability density function given by:</p>
<p>\begin{equation}<br />
f _X\left(x \mid \lambda \right)=\lambda e^{-x\lambda} , x &gt; 0, \lambda &gt; 0<br />
\end{equation}</p>
<p><em>Remember that the mean of this distribution is equal to one over the rate parameter <span class="math notranslate nohighlight">\(\lambda\)</span>, i.e. <span class="math notranslate nohighlight">\(E(X) = \frac{1}{\lambda}\)</span>.</em></p>
<p>We have that the log-likelihood is:</p>
<p>\begin{align}
\log L\left( \lambda \mid \mathbf{x} \right) &amp;= \sum_{i=1}^n \log  L(\lambda \mid x_i) \
&amp;= \sum_{i=1}^n \log \left( \lambda e^{-x_i \lambda } \right) \
&amp;= \sum_{i=1}^n \log \lambda -x_i\lambda \<br />
&amp;= n \log \lambda -\lambda \sum_{i=1}^n x_i
\end{align}</p>
<p>We can make a plot of this log-likelihood, using the data from our example with eight observations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">options</span><span class="p">(</span><span class="n">repr.plot.width</span><span class="o">=</span><span class="m">4</span><span class="p">,</span> <span class="n">repr.plot.height</span><span class="o">=</span><span class="m">3</span><span class="p">)</span>

<span class="c1">#six independent observations for waiting times </span>
<span class="n">obs</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="m">8.75</span><span class="p">,</span> <span class="m">10.20</span><span class="p">,</span> <span class="m">15.29</span><span class="p">,</span> <span class="m">7.89</span><span class="p">,</span> <span class="m">7.04</span><span class="p">,</span> <span class="m">12.04</span><span class="p">,</span> <span class="m">19.04</span><span class="p">,</span> <span class="m">17.50</span><span class="p">)</span>
<span class="n">n</span> <span class="o">&lt;-</span> <span class="nf">length</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

<span class="c1">#possible values for the parameter lambda</span>
<span class="n">lambda</span> <span class="o">&lt;-</span> <span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">0.01</span><span class="p">)</span>

<span class="c1">#plot the log-likelihood</span>
<span class="nf">plot</span><span class="p">(</span><span class="n">lambda</span><span class="p">,</span> <span class="n">n</span><span class="o">*</span><span class="nf">log</span><span class="p">(</span><span class="n">lambda</span><span class="p">)</span> <span class="o">-</span> <span class="n">lambda</span><span class="o">*</span><span class="nf">sum</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;l&quot;</span><span class="p">,</span> <span class="n">xlab</span><span class="o">=</span> <span class="nf">expression</span><span class="p">(</span><span class="n">lambda</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-100</span><span class="p">,</span><span class="m">0</span><span class="p">),</span><span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Log-likelihood&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/06.b. Maximum Likelihood_1_0.png" src="_images/06.b. Maximum Likelihood_1_0.png" />
</div>
</div>
<p>Graphically, we observe that the maximum is between 0 and 0.25. We will use the three steps, as before, to derive the MLE algebraically:</p>
<p><strong>Step1</strong>: Taking the derivative of the log-likelihood with respect to <span class="math notranslate nohighlight">\(\lambda\)</span>:
\begin{equation}
\frac{d log L\left( \lambda \mid x_1 ,â€¦, x_n \right) }{d \lambda} = \frac{n}{\lambda}- \sum_{i=1}^n x_i
\end{equation}</p>
<p><strong>Step2:</strong> Set the derivative equal to zero and solve for <span class="math notranslate nohighlight">\(\lambda\)</span>:
\begin{equation}
0 = \frac{n}{\lambda}- \sum_{i=1}^n x_i
\end{equation}</p>
<p>\begin{equation}
\hat{\lambda}= \frac{n }{\sum_{i=1}^n x_i} = \frac{1}{\bar{x}}
\end{equation}</p>
<p>The MLE is <span class="math notranslate nohighlight">\(\hat{\lambda}= \frac{1}{\bar{x}}\)</span>. And to check that this provides a maximum, we go on to the next step:</p>
<p><strong>Step3:</strong> Find the second derivative:</p>
<p>\begin{equation}
\frac{d l^2 \left( \lambda \mid \boldsymbol{x} \right)}{d \lambda ^2}
= - \frac{n}{\lambda^2}
\end{equation}
When <span class="math notranslate nohighlight">\({\lambda}=\frac{1}{\bar{x}}\)</span>, we have:
\begin{align}
\frac{d l^2 \left( \lambda \mid \boldsymbol{x} \right)}{d \lambda ^2}<br />
&amp;=-n \bar{x}^2
\end{align}
which is negative. This verifies that we found the maximum likelihood estimate.</p>
<p>Going back to our example of eight patients waiting for their GP appointment, the maximum likelihood estimate <span class="math notranslate nohighlight">\(\lambda\)</span> is given by one over the average of the eight waiting times:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="m">1</span><span class="o">/</span><span class="nf">mean</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">0.0818414322250639</div></div>
</div>
<p>We have that <span class="math notranslate nohighlight">\(\hat{\lambda}=0.0818\)</span> minutes.</p>
</div>
<div class="section" id="example-normal-distribution">
<h1>6.1.2 Example: Normal distribution<a class="headerlink" href="#example-normal-distribution" title="Permalink to this headline">Â¶</a></h1>
<p>We will now consider the normal distribution. Remember that the normal distribution has two parameters, <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>. We will first obtain the MLE for <span class="math notranslate nohighlight">\(\mu\)</span> (treating <span class="math notranslate nohighlight">\(\sigma^2\)</span> as a constant), and in the practical, we will obtain the MLE for <span class="math notranslate nohighlight">\(\sigma^2\)</span> (treating <span class="math notranslate nohighlight">\(\mu\)</span> as a constant). Recall that normal distribution has probability density function given by:</p>
<p>\begin{equation}<br />
f_X \left( x \mid \mu, \sigma^2 \right)= (2 \pi \sigma^2)^{-\frac{1}{2}} \exp \left{-\frac{(x-\mu)^2}{2\sigma^2} \right}
\end{equation}</p>
<p>We have that the log-likelihood given an i.i.d. sample of size <span class="math notranslate nohighlight">\(n\)</span> is:</p>
<p>\begin{align}
l \left(\mu, \sigma^2 \mid  \boldsymbol{x}  \right) &amp;=  \sum_{i=1}^n \log \left{ (2 \pi \sigma^2)^{-\frac{1}{2}} \exp \left{-\frac{(x_i-\mu)^2}{2\sigma^2} \right} \right} \
&amp;= \sum_{i=1}^n \left{ \log (2 \pi \sigma^2)^{-\frac{1}{2}}+ \log \exp  \left{-\frac{(x_i-\mu)^2}{2\sigma^2} \right}  \right} \
&amp;= \sum_{i=1}^n \left{ -\frac{1}{2} \log (2 \pi \sigma^2) - \frac{(x_i-\mu)^2}{2\sigma^2}  \right} \
&amp;=  {-\frac{n}{2}}\log (2 \pi \sigma^2) -\frac{1}{2\sigma^2} \sum_{i=1}^n (x_i-\mu)^2
\end{align}</p>
<p>We will first find the MLE for the parameter <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p><strong>Step1</strong>: Take the derivative of the log-likelihood with respect to  <span class="math notranslate nohighlight">\(\mu\)</span>. Note that this requires use of the chain rule:</p>
<p>\begin{align}<br />
\frac{d l \left(\mu, \sigma^2 \mid  \mathbf{x}  \right) }{d \mu}
&amp;=  -\frac{2}{2\sigma^2}(-1) \sum_{i=1}^n (x_i-\mu) \
&amp;=  \frac{ \sum_{i=1}^n (x_i-\mu)}{\sigma^2} \
&amp;=  \frac{ \sum_{i=1}^n x_i-n\mu}{\sigma^2}
\end{align}</p>
<p><strong>Step2:</strong> Setting the derivative equal to zero and solving for <span class="math notranslate nohighlight">\(\mu\)</span>:</p>
<p>\begin{align}<br />
0 &amp;=  \frac{ \sum_{i=1}^n x_i-n\mu}{\sigma^2} \
\end{align}</p>
<p>Since <span class="math notranslate nohighlight">\(\sigma^2 &gt; 0\)</span>, we have that:</p>
<p>\begin{equation}<br />
0 = \sum_{i=1}^n x_i-n\mu
\end{equation}</p>
<p>\begin{equation}<br />
\hat{\mu} =\frac{ \sum_{i=1}^n x_i}{n} = \bar{x}
\end{equation}</p>
<p>We have that the MLE for <span class="math notranslate nohighlight">\(\mu\)</span> is the sample mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>.</p>
<p><strong>Step3:</strong> Find the second derivative:</p>
<p>\begin{align}<br />
\frac{d^2 l \left(\mu, \sigma^2 \mid  \mathbf{x}  \right) }{d \mu^2 }
&amp;=  -\frac{n}{\sigma^2},
\end{align}</p>
<p>since both <span class="math notranslate nohighlight">\(n&gt;0\)</span> and <span class="math notranslate nohighlight">\(\sigma^2 &gt;0\)</span>, we have that the second derivative is negative, verifying that we have found the maximum.</p>
<p>In the practical, we will find the MLE for <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            kernelName: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="06.a.%20Maximum%20Likelihood.html" title="previous page">6. Maximum Likelihood</a>
    <a class='right-next' id="next-link" href="06.c.%20Maximum%20Likelihood.html" title="next page">6.2 Properties of maximum likelihood estimators</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By MSc Health Data Science, LSHTM<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>