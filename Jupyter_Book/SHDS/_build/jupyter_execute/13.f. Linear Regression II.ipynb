{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.5 Including higher-order terms and interaction terms in a linear regression model\n",
    "\n",
    "As we have already discussed, linear regression assumes that the relationship between the outcome and the independent variables is linear. As we already know, this is not always the case in real data. For example, suppose we are interested in the association between weight and age. On average, the weight of young adults will increase with age. However, at a certain age, the average weight may start to decrease. In this case, the association between weight and age would follow a non-linear (upside-down) $u$-shape. It could still be possible to model this relationship within the linear regression framework, by adding a **second-order term** to the model. This procedure is known as **quadratic regression**. \n",
    "\n",
    "Now suppose we are interested in relating weight to age, sex and height (weight is the outcome and age, sex and height are the covariates). In this case, the estimated regression coefficient for height represents the effect of a unit increase in height on weight in people of the same age and sex. The model assumes that the coefficient relating weight to height is the same for all people of all ages and sexes. For example, that it is the same for two year old boys as in thirty-three year old women. But this is not necessarily true! It could be that the slope of the association between weight and height differs by sex and by age. If this is the case, we say there is an **interaction** between height and sex and between height and age. \n",
    "\n",
    "In this section we will first learn how non-linear relationships can be accounted for in quadratic regression, then learn how to include interaction terms in a linear regression model. \n",
    "\n",
    "\n",
    "### 13.5.1 The quadratic regression model \n",
    "\n",
    "The quadratic regression model is a multivariable regression model with two independent variables where the second variable is the square of the first variable. Algebraically:\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\epsilon \\text{ where } \\epsilon \\sim NID(0,\\sigma^2)\n",
    "$$ \n",
    "\n",
    "Despite the fact that one of the variables is the square of the other, this is still a linear regression model because the expectation of the outcome is a linear function of both parameters. \n",
    "\n",
    "The figure below shows two scatter plots of the data used in Scenario A above. The plot on the left-hand side includes the fitted values of a linear regression model (with no higher-order terms included) and the right-hand side plot includes the fitted values of a quadratic regression model. By comparing the plots, we can see that the quadratic regression model does have a better fit, particularly at the extreme values of $X$. \n",
    "\n",
    "```{figure} Images/quadratic_example.jpg\n",
    "---\n",
    "height: 600px\n",
    "name: quadratic_example\n",
    "---\n",
    "```\n",
    "\n",
    "Unfortunately, interpreting $\\beta_1$ and $\\beta_2$ is not as straightforward as in most linear models. The reason for this is that it is not possible to change $X^2$ by 1 unit whilst holding $X$ constant (although it is possible the other way round). Moreover, quadratic regression models are limited in terms of describing relationships between variables in most medical applications. Quadratic functions either increase to a maximum and the decline, or fall to a minimum and then increase. Further, the behaviour of a quadratic is symmetric about the turning point. Such relationships in medical research are rarely plausible. \n",
    "\n",
    "However, the quadratic regression model can be useful as a test for non-linearity. Quadratic terms can be added to a regression model with more than one covariate, and if the results indicate that the quadratic term is an important variable, this is indicative of curvature in the relationship between the outcome and the variable of interest. This often motivates fitting a more realistic model to better describe the non-linear relationship.\n",
    "\n",
    "*Example*. We will use quadratic regression to assess the linearity assumption for the covariates in Model 3 (recall Model 3 relates birthweight to length of pregnancy and mother's height). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in data$Gestational.Days: object of type 'closure' is not subsettable\n",
     "output_type": "error",
     "traceback": [
      "Error in data$Gestational.Days: object of type 'closure' is not subsettable\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#Define the squared terms\n",
    "data$Gestational.Days.squared<-data$Gestational.Days*data$Gestational.Days\n",
    "data$Maternal.Height.squared<-data$Maternal.Height*data$Maternal.Height\n",
    "\n",
    "#Quadratic regression to test the linearity between birthweight and gestational days\n",
    "model_test1<-lm(data$Birth.Weight~data$Gestational.Days+data$Maternal.Height+data$Gestational.Days.squared)\n",
    "summary(model_test1)\n",
    "\n",
    "#Quadratic regression to test the linearity between birthweight and mother's height\n",
    "model_test2<-lm(data$Birth.Weight~data$Gestational.Days+data$Maternal.Height+data$Maternal.Height.squared)\n",
    "summary(model_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that the squared terms for gestational days and mother's height are not important (as indicated by lack of small $p$-values), therefore we can assume that linearity has not been violated. This is consistent with our conclusions based on the normal residual plot. \n",
    "\n",
    "In the next section, we briefly discuss some statistical options for modelling non-linear associations more realistically, when the linearity assumption is not met and the quadratic regression model is not appropriate. \n",
    "\n",
    "\n",
    "#### 13.5.1.1 More complex modelling of non-linear associations \n",
    "\n",
    "The quadratic regression model belongs to a family of **polynomial regression models** and is the simplest model in that family. Further power terms can be added to the regression model in order to increase complexity. For example, a cubic regression model is one which includes a cubic term as well as a squared term. \n",
    "\n",
    "An even more flexible approach is to use a **piecewise polynomial model**, which allows for a different polynomial function in different ranges of the observed values of $X$, defined according to specified **knots**. For example, a piecewise cubic polynomial model with two knots at $k_1$ and $k_2$ ($k_1 < k_2$) takes the form:\n",
    "\n",
    "$$ \n",
    "y_i = \n",
    "\\begin{cases}\n",
    "\\beta_{01} + \\beta_{11}x_i + \\beta_{21}x_i^2 + \\beta_{31}x_i^3 + \\epsilon_i \\text{ when } x_i < k_1 \\\\\n",
    "\\beta_{02} + \\beta_{12}x_i + \\beta_{22}x_i^2 + \\beta_{32}x_i^3 + \\epsilon_i \\text{ when } k_1 \\leq x_i < k_2 \\\\\n",
    "\\beta_{03} + \\beta_{13}x_i + \\beta_{23}x_i^2 + \\beta_{33}x_i^3 + \\epsilon_i \\text{ when } k_2 \\geq x_i\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    " \n",
    "The flexibility of the model (and therefore its ability to model more complex relationships) can be increased by increasing the degree of polynomial and/or the number of knots. However, highly flexible models may overfit the data and make the model difficult to interpret. In general, it is a good idea to consider an appropriate trade-off between flexibility and interpretability. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}