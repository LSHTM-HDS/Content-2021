{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 9.1 Introduction to Bayesian Inference\n",
    "\n",
    "### 9.1.1 Probability \n",
    "In Session 2, we learned about probability in the frequentist sense: the proportion of times an event occurs in the long-run. Let's have a look at the following two scenarios:\n",
    "\n",
    "1. A research group wishes to know the probability that a baby who is born in a particular hospital ward has cystic fibrosis. They look at the records on screening tests done at birth to investigate.  \n",
    "\n",
    "2. A 34 year old woman attends her GP practice, worried that she has cancer because she has had feelings of “fullness” and “bloating” as well as mild nausea for the last 2 weeks. The patient mentions ovarian, bowel and pancreatic cancer as concerns having read about her symptoms on the internet. The rest of the history as well as physical examination are unremarkable. If the GP's assessment of the risk were above a certain level, the GP might refer the patient for tests (collect more data). In this case, the GP concludes that the current information about the patient suggests there is a very low risk that the patient has cancer. \n",
    "\n",
    "> What is the quantity that we trying to estimate in each scenario?   \n",
    "> What is the frequentist definition of probability in each of these settings? Does it make sense?    \n",
    "\n",
    "A key problem with the frequentist paradigm is that the \"long-run\" frequency definition is not always relevant, or even appropriate, as we see in the second example above. Further, notice that the GP uses information from different sources to draw his/her conclusion about the probability that the patient has cancer. This synthesis of information can be incorporated into a Bayesian framework. A frequentist, in contrast, would tackle this problem by thinking about:\n",
    "\n",
    "> a) the probability of the patient having these symptoms, given that she has cancer;  \n",
    "> b) the probability of the patient having these symptoms, given that she does not have cancer; \n",
    "\n",
    "and comparing the two probabilities. Note that this does not take into account the extra information about the context. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.2 Bayesian Inference \n",
    "\n",
    "The underlying concept for Bayesian inference essentially works as follows. We have some population parameter $\\theta$ which we wish to make inference on, and the likelihood $p(y|\\theta)$ which tells us how likely different values of $y$ are, conditional on different parameter values $\\theta$. In the frequentist approach, $\\theta$ is considered to be a fixed, but unknown, constant. Inference is then based on the likelihood $p(\\mathbf{y}|\\theta)$, where $\\mathbf{y} = \\left\\{y_1, . . . ,y_n\\right\\}$ is a sample of observations from the population. The frequentist approach looks at the distribution of the data given $\\theta$ to estimate $\\theta$ by using, for example, the maximum likelihood approach which we covered in Session 6.   \n",
    "\n",
    "In the Bayesian paradigm, we no longer assume that the parameters have a fixed true value, but consider $\\theta$ to be a random quantity with an unknown distribution, which we wish to estimate. This distribution is denoted by $p(\\theta|y)$, and so we look at the distribution of the parameter, having seen data $y$. To achieve this, we will have to specify a prior probability distribution, denoted $p(\\theta)$, which represents our initial beliefs about the distribution of $\\theta$ \n",
    "prior to observing any data. In some situations, when we are trying to estimate a parameter $\\theta$ we have some knowledge, about the possible value of $\\theta$ before we take into account the data that we observe.   \n",
    "\n",
    "For example, consider the way a physician makes diagnostic decisions. A patient presents with a set of symptoms, concerned that they might have a certain disease. The physician assesses the probability that this patient has this disease, based on symptoms, family history, alternative explanations of symptoms and prevalence of the disease (their prior view that the patient has the disease). The physician might send the patient for a diagnostic test (collects some data) if her prior assessment of risk is above some threshold. Then the physician re-assesses the chance that the patient has this disease, taking account of the results and reliability of the diagnostic test (updates their prior in light of the data to get a posterior view on whether the patient has the disease). Depending on their certainty, the physician may then send the patient for further diagnostic tests. This thought process can be represented by the figure below and is analogous to Bayesian thinking.\n",
    "\n",
    "   ![Physician.png](attachment:Physician.png)\n",
    "\n",
    "In this example, the physician is assessing the probability that the patient has the disease. It is the physician's prior probability based on their own training, knowledge and experience; a colleague may have a different prior probability. Here, prior probability is being defined subjectively. The size of the probability represents the physician's degree of belief about the occurrence of an event, i.e. their own personal assessment of how likely an event is, based on the evidence available to them before the test results are given. This definition corresponds more closely to the everyday, intuitive  usage of probability than a frequentist interpretation (where the probability of a particular event occurring can be interpreted as the proportion of times the event would/does occur in a large number of similar trials or situations). The prior probability of the event might come from direct data, known prevalance of disease in a population, or data from related populations. If such prior information does not exist, then it can be formally elicited from experts, but we would want to acknowledge the uncertainty in the experts' knowledge.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 9.5 Bayes Theorem \n",
    "\n",
    "Let's remind ourselves of Bayes theorem for discrete events, which we met in Session 2 (probability): \n",
    "\n",
    "If $A$ and $B$ are events, then \n",
    "\n",
    "\\begin{equation}\n",
    "P(A|B) = \\frac{ P(B|A) P(A) } {P(B)} \\propto P(B|A) P(A),\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "or in words: \n",
    "\\begin{equation}\n",
    "\\mbox{posterior probability of A given B} \\propto \\mbox{the likelihood of B given A} \\times \\mbox{the prior probability of A}.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Also, if $A_i$ is a set of mutually exclusive and exhaustive events, i.e. $ p( \\bigcup\\limits_i A_i ) = \\sum\\limits_i p(A_i) = 1$ and $A_i \\cap A_j = \\emptyset$ for $i \\neq j$, then \n",
    "\n",
    "\\begin{equation}\n",
    "p(A_i|B) = \\frac{ p(B|A_i) p(A_i) } {\\sum\\limits_j p(B|A_j) p(A_j) }.\n",
    "\\end{equation}\n",
    "\n",
    "The calculation of the denominator is more difficult if we have continuous parameters as it requires integration over A; we will discuss this in the next section.   \n",
    "\n",
    "We will illustrate Bayes Theorem further with the diagnostic test example for Covid-19 below. We see Bayesian reasoning is purely probabilistic. Bayes theorem gives us a principled way to update prior probabilities on the basis of new data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9.6 Example \n",
    "\n",
    "[Watson (2020)](https://www.bmj.com/content/bmj/369/bmj.m1808.full.pdf) discusses some interesting issues around the interpretation of Covid-19 diagnostic tests. Typically, a clinician estimates a pre-test probability (a prior probability) of having Covid-19 for a particular area, which is derived from knowledge about local rates of Covid-19. Then, given a patient's test result, the post-test probability (the posterior probability) of having Covid-19 is obtained. The posterior probability depends on the pre-test probability, as well as the sensitivity and specificity of the test, which are difficult to estimate; often, sensitivity is over-estimated. The article discusses how one can be fairly confident about a positive test result, but more caution is needed for a negative test result, as there may still be quite a high chance that a person has Covid-19. We illustrate this with Bayes' theorem. \n",
    "\n",
    "Suppose that, in a student hall of residence, the prevalence of Covid-19 if you have a persistent cough is $75\\%$. Suppose we assume that the test will be positive in Covid-19 patients $70\\%$ of the time (sensitivity is 0.7), and it will be negative in non-Covid-19 patients $95\\%$ of the time (specificity is 0.95). Given that a student in this hall with a persistent cough tests negative, what is the probability that they have Covid-19? In other words, what is the probability of a false negative?  \n",
    "\n",
    "Let us denote by $C+$ the event that a person has Covid-19, and $C-$ the event that a person does not have Covid-19.  Further we denote by $T+$ and $T-$ the events that a person has a positive and a negative test, respectively. The information we are given is that: \n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "p(C+)&=0.75  \\\\\n",
    "p(T+|C+)&=0.70 \\\\\n",
    "p(T-|C-)&=0.95\\\\\n",
    "\\end{align}\n",
    "\n",
    "Now, what we want is:\n",
    "\\begin{align}\n",
    "p(\\mbox{false negative}) = p(C+|T-)&= \\frac{p(T-|C+)p(C+)}{p(T-)} \\\\\n",
    "&= \\frac{p(T-|C+)p(C+)}{p(T-|C+)p(C+) + p(T-|C-)p(C-)} \\\\\n",
    "&= \\frac{(1-0.7) \\times 0.75}{(1-0.7) \\times 0.75 + 0.95 \\times 0.25} \\\\\n",
    "&= \\frac{0.225}{0.4625} \\\\\n",
    "&= 0.4864\n",
    "\\end{align}\n",
    "\n",
    "You can see that, despite the negative test result, due to the very high prevalence of Covid-19 in the hall of residence and the relatively low sensitivity rate, there is still a 48.64% chance that a person has Covid-19.  \n",
    "\n",
    "Suppose a different student has no symptoms. The prevalence of Covid-19 in asymptomatic people is 0.1. They use the same diagnostic test and the test result is positive. What is the probability that this student with a positive test result has Covid-19? In other words, what is $p(C+|T+)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n",
    "\\begin{align}\n",
    "p(C+|T+) &= \\frac{p(T+|C+)p(C+)}{p(T+)} \\\\\n",
    "&= \\frac{p(T+|C+)p(C+)}{p(T+|C+)p(H+) + p(T+|C-)p(C-)} \\\\\n",
    "&= \\frac{0.7 \\times 0.1}{0.7 \\times 0.1 + (1-0.95) \\times 0.9} \\\\\n",
    "&= \\frac{0.07}{0.115} \\\\\n",
    "&= 0.609\n",
    "\\end{align}\n",
    "\n",
    "This means that, amongst all the people who test positive, $60.9\\%$ will actually have the disease. After a positive result from a test, the probability that you have Covid-19 increase from $10\\%$ to $61\\%$.\n",
    "\n",
    "Note that these results are specific to the the prevalence of Covid-19 in the area, as well as the sensitivity and specificity of the diagnostic test. The code below reproduces the leaf-plot from [Watson (2020)](https://www.bmj.com/content/bmj/369/bmj.m1808.full.pdf). The $x$-axis is the pre-test probability of having Covid-19. The corresponding $y$-values on the lower curve (lower leaf) are the post-test probabilities of having Covid-19, following a negative test result. The corresponding $y$-values on the upper curve (upper leaf) are the post-test probabilities of having Covid-19, following a positive test result. The correponding values on the diagonal ($y=x$) line represent probabilities if no test is carried out. \n",
    "\n",
    "In our first example, the prevalence in symptomatic people is 0.75, so we follow the orange arrows to find that the post-test probability after a negative result 0.4864. In the second example, the prevalence in asymptomatic people is 0.1. We follow the purple arrows to find that the post-test probability after a positive result is 0.609. How do you think the shape of the lower and upper leaves would change, if sensitivity was higher? If specificity was lower? Re-run the code with different values to check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwwAAAKUCAMAAACe40/TAAAAOVBMVEUAAAAAZABNTU1oaGh8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\nA4DlfwzB49jrY+XzAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function takes as arguments the sensitivitiy of the test (sensi) \n",
    "# and the specificity (speci)\n",
    "\n",
    "leafplot <- function(sensi, speci){\n",
    "  \n",
    "  pretest <- seq(0, 1, 0.01) #possible pre-test probabilities \n",
    "  \n",
    "  #probability of having Covid-19 after a positive test result \n",
    "  pos.test <- sensi*pretest/(sensi*pretest+(1-speci)*(1-pretest))\n",
    "  \n",
    "  #probability of having Covid-19 after a negative test result \n",
    "  neg.test <- ((1-sensi)*(pretest))/((1-sensi)*pretest+speci*(1-pretest))\n",
    "  \n",
    "  #plot leaves\n",
    "  plot(pretest, pos.test, type=\"l\", col=\"darkgreen\", \n",
    "     xlab=\"Pre-test Probability\", ylab=\"Post-test Probability\")\n",
    "  points(pretest, neg.test, type=\"l\", col=\"darkgreen\")\n",
    "  abline(a=0, b=1, col=\"darkgreen\")\n",
    "  legend(\"topleft\", legend=c(\"Positive Test\", \"Negative Test\"),\n",
    "        col=c(\"Purple\", \"Orange\"), lty=1, bg=\"transparent\")\n",
    "  \n",
    "  #plot arrows \n",
    "    #we use pretest[11] to get the prevalence value of 0.1, and \n",
    "    #pretest[76] to get the prevalence value of 0.75 in the vector \"pretest\"\n",
    "    \n",
    "  arrows(pretest[11], 0, pretest[11], pos.test[11], angle=15, col=\"purple\")\n",
    "  arrows(pretest[11], pos.test[11], 0, pos.test[11], angle=15, col=\"purple\")\n",
    "  arrows(pretest[76], 0, pretest[76], neg.test[76], angle=15, col=\"orange\")\n",
    "  arrows(pretest[76], neg.test[76], 0, neg.test[76], angle=15, col=\"orange\")\n",
    "  \n",
    "  }\n",
    "\n",
    "options(repr.plot.width=6.5, repr.plot.height=5.5)\n",
    "leafplot(sensi=0.7, speci=0.95)\n",
    "\n",
    "\n",
    "#See what happens to the plot when you change sensitivity and specificity! \n",
    "#leafplot(0.95, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.7 The Bayesian paradigm in Health data science problems. \n",
    "\n",
    "We end this section with a discussion on the Bayesian approach in Health data science problems. Some features of the Bayesian paradigm are particularly useful in this context: \n",
    "> 1.\tBayes theorem provides a statistically principled method for combining data. Thus, we can take into account the context within which the data are generated. For example, results of a diagnostic test may have a different interpretation/consequence if used in a symptomatic patient than in a general screening programme. The prior probability of disease would be higher in the former than the latter. Priors can then be updated by the test result to give an assessment of disease risk specific to the local prevalence.\n",
    "> 2.\tFor problems where there are multiple or diverse sources of data which must be combined, the Bayesian framework provides a natural environment for doing so. Examples where Bayesian synthesis of information is common are:         \n",
    "•\tmodels of biological systems, for example genetic and genomic pathways,                     \n",
    "•\tmodels of the natural history of diseases over time and relationships with clinical events,           \n",
    "•\teconomic models of disease trajectories and cost-effect trade-offs for interventions that interrupt the trajectories,   \n",
    "•\tecological studies of pollutant emissions and effects on population health,       \n",
    "•\tdemographic studies, for example to study migration,          \n",
    "•\tspeech recognition software,                 \n",
    "•\tother pattern recognition models such as medical imaging or search engines,                 \n",
    "•\tepidemic modelling.                       \n",
    "In all these examples complex data is synthesised and/or used to update outputs.             \n",
    "> 3.\tBayesian models fit well into decision theory methodology, providing we can also specify consequences of model outputs.\n",
    "> 4.\tIn many examples, especially those that aim to model complicated processes, some of the data inputs are very sparse, or even non-existent. In such cases, prior data may be formally elicited from an expert panel and incorporated in a Bayesian analysis. Examples include multiple evidence synthesis and identification of latent groups.\n",
    "> 5.\tBayesians are allowed to make direct probability statements about unknown quantities. Frequentists cannot make these direct probability statements because the unknown model parameters are assumed fixed.\n",
    "> 6.\tIn recent years the resources available to complete Bayesian analysis have increased, including bespoke software and packages within commercial statistical software.\n",
    "\n",
    "But Bayesian methods are not that widely used in statistics compared with more classical approaches because they have some limitations.\n",
    "> 1.\tSometimes the need for a prior distribution is a barrier if little is known about a parameter and researchers fall back on priors that are weakly informative. In that case, it is not easy to see how much benefit comes from a Bayesian analysis.\n",
    "> 2.\tBecause of the need to use Bayesian updating via a prior distribution, the analysis almost always requires a parametric approach. This limits the structure of the analysis models. Although non-parametric Bayesian methods are available for some situations, they often have underlying parametric assumptions.\n",
    "> 3.\tThe numerical integration methods usually required for realistic problems are often computationally expensive. This is especially true if there are multiple sources of evidence to be combined.\n",
    "> 4.\tMany statisticians are unfamiliar with the methods and associated software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
